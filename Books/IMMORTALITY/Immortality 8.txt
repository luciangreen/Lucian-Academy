["Green, L 2022, <i>Immortality 8</i>, Lucian Academy Press, Melbourne.","Green, L 2022",1,"Immortality 8

1.  I found a bug in which code isn't in a separate predicate.  Unlike Immortality 7, paragraph 80, I found a single predicate with reused code from another predicate.  I moved the reused code into a new predicate with an appropriate head and called this predicate from the other two predicates.  I also identified \"manual recursion\", i.e. a single predicate with a fixed number of recursions, and changed it to multiple predicates.  Also, I determined that findall within the initial predicate could be moved to a new predicate with recursion if recurring variables were required.
2.  I allowed the assumption when the student had understood it when interpreting the student's thoughts to help them write algorithms, an example of a big algorithm represented by an essay.  I found algorithms that were combinations of all ideas in an article.  As part of this, I found the best synthesis of the ideas. Next, I ordered the objects within objects. Finally, I wrote short stories connecting the ideas represented by the objects.

3.  I wrote algorithms to connect sentences, paraphrase and simplify each step towards a longer algorithm to one or two predicates.  I gave an error on [1,\"|\",2,3] but not on [1,\"|\",[2,3]] because a list tail couldn't have two variables.  I also chose to write longer algorithms with artificial intelligence.  Separately, I wrote different predicates to put and get unified variables and simplify lists.  I simplified [1,\"|\",[2,3]] to [1,2,3].
4.  I connected (simplified) predicates from the sentence, possibly generating, selecting and saving names and data for a predicate.  I wrote predicates with single functions, using retry to write the string to list algorithm.  I found the elements of an algorithm, separating them into different predicates if possible and possibly simplifying them.  I considered running one after another and reusing them.  I used the skip command to test a predicate and the retry command to help edit it if it failed.
5.  I noticed the employees, students and customers returned.  I wrote each predicate, for example, an interpreter in one or two predicates.  For instance, I added 1+1.  I kept on adding numbers to the total.  Finally, I wrote a trace predicate.
6.  I deleted obsolete states in the algorithm.  At first, I wrote the database of predicates for philosophical or business purposes.  Using this, I could support other employees.  I could impress employers and head staff.  As part of this, I minimised a set of algorithms.
7.  I predicted a sentence's predicate.  I did this by finding the algorithm for the logical data structure in the sentence.  For example, I inverted an algorithm.  Then, I wrote a short sentence describing the function name and data.  I could identify these later. Finally, I found the predicate from synonyms for the sentence or the function name.
8.  Ontologies may be syno-specifications (with memorable sentences and uses with data).  As part of this, I wrote ontologies connecting possible sentences to predicates. As a first step, I entered the sentence's predicate. Then, I entered words from the sentence associated with inputted words.  Later, I could find the predicate from these inputted words.
9.  The student entered the shorter algorithm to demonstrate her understanding.  I was free to determine how much work I did.  I could write new algorithms when necessary.  I could work when I wanted to.  I found the algorithms from longer algorithms.
10.  I mind read the predicate.  As part of this, I started with the list of possible predicates. Then, I broke these predicates into decomposition, transformation and the list building parts.  Next, I mind read different possibilities at each point. Finally, I checked the link from the sentence to the algorithm.
11.  I perfectly programmed the essay.  I did this by mind-reading the sentence.  Then, I split the sentence into grammatical parts. Next, I converted it to logic (methodical and data structures). Finally, I found the sentence for the predicate.
12.  Mind reading, decision tree mind reading in particular, suggested thoughts to students.  I mind read the student thinking of a predicate using a decision tree, helping them deserve details (or enough for part of an A).  I grouped them by command and variable in the decision tree.  Using the decision tree with the mind reader gave more considered results.  Mind reader detected a thought from an options list if the user took less time to think of a breasoning, the x, y and z dimensions of an object, using meditation.
13.  Learning the algorithm names became like learning keys, saving time.  Regularly writing predicates helped me write efficiently.  I wrote list processing in the predicate head.  I could invert the predicate also using cut.  I worked out the predicate or identified its input and output and found its name.
14.  CAW could work with the program finder with types to narrow down commands. For example, I used CAW to check I had optimised predicates.  I also stored predicate names and variables as a,b,c, etc.  If there were up to four commands, I verified that the predicate was optimised using CAW.  CAW sorted and found the commands in the same order each time.
15.  I inserted a command that called other commands.  I used the program finder with types to check I had optimised predicates.  I found the list within the string.  I found a string within this list.  I repeated this.
16.  I used and deleted unused functional commands.  I used the user interface to write the predicate.  I found a.b and c.b rather than (a,c).b.  However, I could use other brackets and save results.  I could press tab to expand or contract commands, with dynamic results.
17.  I also used the graphical user interface to write the predicate.  I typed the predicate one character at a time.  I could construct input and output while I typed.  The input and output helped predict the code.  I could indicate input and output with specific uses, with some prioritised based on the sentence.
18.  I converted back to an algorithm with documentation about the uses of predicates in the program. First, I chose the shortest predicates from my algorithms and converted them from names to descriptions. Next, I increased or decreased algorithms to predicates. Finally, I removed unnecessary predicates, minimising the algorithm's state machine.

19.  I stored the logical structural parameters in a text file.  I wrote the logical structure of List Prolog Interpreter (LPI) (not, or, if-then) with functionalism.  I did this by writing the command names.  I also wrote the logical relation. Finally, I checked that the relevant commands had returned true.
20. I inverted a.b (=b^-1.a^-1) and explained a.(b.c) (=a.b.c). I made LPI more complex with more features.  I listed original features.  I listed the ISO features.  I listed features of other programming languages and inductive algorithms.
21.  I instantiated values to find before, not after searches, for example, searching in strings.  I simplified the features of LPI.  I used invertible functions to save time.  I used the function once without inverting it straight away.  Simplifying constraint-finding algorithms was critical, for example member(A,[1,2,3]) and member(B,[1,2,3]), etc. A=1,B=1 can be simplified to A=3,B=3,member(A,[1,2,3]),member(B,[1,2,3]) (much faster) even deleted.
22.  I passed the ball back to the facilitator when I could run the command.  In multithreading, I ran the concurrent processes with mutexes (code that stops a piece of code from being run at the same time twice).  When multithreading, I wrapped each predicate call or command in a mutex.  I couldn't run these parts concurrently and waited until one had finished before running it.  I tried running commands one at a time, waiting to run commands when they were non-mutexed.
23.  I mutex-unlocked the command when it had finished.  Prolog mutexes are recursive, meaning the algorithm must remove multiple mutex layers added with recursion before another thread can access the resource.  They also wrapped any command, such as findall, not or if-then.  If a command was mutex locked, it couldn't run.  The interpreter stored mutex locking in the heap (where the globals are), and threads have their stacks.  Each predicate ID had a mutex lock status.
24.  I stored stacks for local (current predicate) and global choice points and new ones for the call command, in addition to thread stacks.  I made a copy of the stack for each thread and used the same heap (predicates, globals, etc.).  In SSI, each frame of the interpreter (for example, running a command or exiting a predicate) of each thread ran one at a time.  I could collect SLG tabling data with mutexes, saving time by using past results of previously run predicates.  A command with an SLG tabling entry didn't need to I run or mutex locked.
25.  I wrote an algorithm that simulated multithreading that ran one command of each list at a time, which took longer than usual because it ran an interpreter.  Aside from this, I made copies of stacks for threads. Then, when I created a new thread, I copied the stacks to a new set of stacks.  I used these to run the commands in the thread until they exited.  Then, the interpreter merged the stacks and updated the variables.
26.  I considered using a computer with multiple processors.  Also, multithreading with copies of the stack helped performance.  For example, I tried text to breasoning with multithreading.  I also tried mind reading with multithreading. Finally, I tested for better performance with multithreading, more threads and more processors.
27.  I questioned multithreading with one processor or one computer.  I used a server with more CPUs or processors.  multithreading improved results on this machine.  I agreed with adumbrations while working on solutions during my life.  I did all the thinking while the computer found solutions using brute-force algorithms.
28.  Multithreading improved performance in operating systems.  I could multi-task (run different applications at the same time).  I chose to be well-known by writing some algorithms using neural networks.  I could do things in terms of my life.  I could save time and spend time doing other things.
28.  I gave SLG tabling as the reason for mutexes.  Mutexes were necessary with immutability separately because mutexes protected the same resources with changing references from being reused.   Immutability only allowed one value per variable.  A mutexed command only allowed one processor to run it at a time.  In this way, they were unrelated.
29.  Multithreading in Prolog used C to handle memory, where Prolog ran one command at a time on each thread.  Prolog lined up the threads.  The interpreter ran the current command of each thread.  If a thread mutexed a command, the other threads couldn't run it until it had become unmutexed.  If it didn't matter which predicate finished first, they could be multi-threaded.  A command which possibly didn't count could be multi-threaded.
30.  Multithreading possibly took the same time to run as without, but some parts finished earlier, speeding up performance.  Mutexes sped up performance when the interpreter ran the same command.  An advanced algorithm chose to run threads that solved bottlenecks first.  This algorithm considered the likely length of a recursive command when selecting the order of threads.
31.  I considered using the fastest algorithms.  I cancelled a thread that was taking too long.  I timed parts of the thread.  If it took too long, or the useful results had been found, I cancelled it.   I could reorder parts of or cancel threads that caused bottlenecks.
32.  Once one algorithm had finished, the next was run, with opportunities to pause or recontinue at different points. First, I manually queued algorithms on parallel processors. Then, I connected computers to a server.  These computers downloaded files to process.  They uploaded the results.
33.  The prediction thread ran in the background while another thread waited for input.  I ran commands while the user was inputting data, giving predictions.  The user entered the start of a sentence or algorithm.  The algorithm predicted and offered possible endings.  It used a program finder with types (which could find conditions such as pipes (\"|\") for wrapping in brackets, etc.), Combination Algorithm Writer (CAW) (which recognised indices, need for reused translators or paraphrasers) or a neural network.
34.  I viewed the results of the algorithm.  I ran commands on the server while a web page presented live updates.  The results of the legs of threads affected the next leg of threads.  Threads were created or destroyed based on previous data.  A monitor displayed current and past threads and results.

35.  I found conditions in terms of variables with previous algorithms.  I wrote the whole interpreter with the program finder.  Then, I found the required algorithms with the program finder.  Next, I matched the mathematical specifications for the interpreter (e.g. a_i,...,a_n-><sorted list>).  Then I matched them with mathematical specifications from the required algorithms.  For example, the sort command was described using an algorithm and identified using run-all when there were numbers that didn't fit another pattern.  Finally, I tested for conditions based on the small number of variables.
36.  If there were two instances of a value in the specifications, I checked the other data sets to test if a character recurred and had a single symbol.  I found and worked out additional levels (for each predicate) of mathematical specifications (character a_1 = number, etc.) within the data (input and output, etc. for the algorithm).  I found the data, for example, [a,1,a].  I found the algebraic types [character 1, number 1, character 1].  I found the mathematical specifications, [a_1,a_2,a_1] where a_1=a=character, a2=1=number.
37.  Priority groups (for example, mathematical, file or grammar predicates) may be determined by the user with include statements or artificial intelligence that predicts their need.  I found as much as possible with program finder with types (PFT) before Combination Algorithm Writer (CAW) was needed.  Combination Algorithm Writer was required when, for example, when patterns of data became unpredictable and I may need other predicates.  I may find items to try with run all (or CAW) using program finder.  I considered data types, priority groups and further rounds of use of PFT or CAW.
38.  I needed to skip over finding detailed code segments to achieve larger goals with neural networks (and compared program finder with types with neural networks).  I found the rest of the code (after using program finder) (where there is an unknown connection to the code from the mathematics specification) with a neural network.  I found the maximum number of code lines with the program finder.  Then, I found code for unexplained parts of data, described with mathematics specifications ([[a_1, a_2,..., a_n], [a_n,..., a_2, a_1]]) with a neural network.  A neural network could find short sequences of commands with positive and negative data.
39.  I prevented duplicate code in the neural network and added new code to it.  I added the finished code found with neural networks to the database rather than rebuilding the neural network each time.  I could see and modify the code before adding it to the database.  I could delete code in the database.  I could delete duplicate code in the database.
40.  I checked whether seemingly too simple code might be enough.  Occasionally, the algorithms might return code that appears to answer the question but is too simplistic.  Next, I checked whether the algorithms had \"cheated\" (literally used specifications or not created general rules).  I removed these codes.  I removed them, except if the rule was elementary, for example, \"and\" or \"or\".
41.  I deleted the infinite loop anyway.  I aimed to identify obsolete code (for example, code solved with lazy evaluation).  First, I found infinite loops that lazy evaluation would skip over if they were deleted before returning output, and deleted them.  Second, I verified whether the code was always likely to be obsolete.  Third, I checked whether the interpreter arbitrarily or always skipped the infinite loop.
42.  First, I found reverse with program finder with types, and then I found I needed it with mathematical typing.  I found the predicate for reversal with program finder with types with the mathematical specification a_1...a_n -> a_n...a_1.  Then, I found the mathematical specification.  Then, I looked up the matching mathematical specification for reverse.  I returned the reverse predicate.

43.  I counted the times I had used an algorithm, discarding it if I didn't use it a certain number of times in a period.  I generated many algorithms with a program finder with types.  I developed more obvious algorithms with a program finder with types.  I generated and set the usage count to 0 of algorithms, where I generated them given data.  I also developed morphs of algorithms.
44.  I skipped over generating algorithms but found them with a program finder with mathematical specifications.  I generated algorithms with mathematical specifications.  The mathematical specifications could have recursive definitions.  Also, they could have lists.  These lists could be partially complete or have optional items.
45.  I found the reverse string command.  I combined algorithms with a program finder with types to find new algorithms, for example, reverse and string concat.  I did this by generating algorithms with reverse and string concat.  I started by finding the input and output of algorithms with reverse and string concat.  I then found the intermediate input and output of algorithms with reverse and string concat.
46.  I found lateral associativities.  I added the algorithm to the database and used it after matching it with mathematical specifications.  I did this by finding an algorithm.  Next, I ran it from within another algorithm.  Then, I did this repeatedly.
47.  Alternatively, I used brute force to find the item.  I found a quantum search algorithm.  I did this by mind-reading the item number.  Or, I mind-read the group number.  Alternatively, I mind-read the classification.
48.  I checked the result with mind-reading.  I started by finding a neural search algorithm.  This algorithm considered the query.  It also considered the structure of the database.  In addition, it considered past algorithms and results.
49.  I corrected human errors and found philosophical sources.  I did this by finding a quantum neural search algorithm.  First, I mind-read the location.  Then, I checked this with a neural network.  I could have repeated this.
50.  I found lists of lists used in various places.  I found the algorithms I wanted, for example, using lists of lists as variable data. Then, I wrote the lists of single-item transformations. Finally, I wrote the mathematical changes in lists of lists.  For example, there may be one tail item and how a list as a tail item is simplified.
51.  I also changed SSI to support _1, _2, etc.  I made undefined variables instead of empty values back-compatible with non-equals4 mode.  I changed the value of undefined variables from empty to _1, _2, etc.  I changed equals4 mode to support this.  I changed the non-equals4 mode to support this.  
52.  I found intersection, union and delete.  I found the member command with PFT.  I wrote the input and output.  I detected the need for the \"interpret\" body predicate.  I noticed the need for variables.
53.  I translated an internationalised version of my software.  I translated words that would be outputted.  I detected when I needed to translate words to be written to the screen or outputted.  This was when a translated version was required.  Also, I specified the languages and type of translation.
54.  I found a spoken language from computer code.  I also created a translation dictionary of words that I often translated.  I did this by collecting words to translate.  I had previously found the required languages.  Then, I translated them.
55.  SSI used the same equals4 system as List Prolog Interpreter.  I developed the equals4 mode in List Prolog Interpreter, which allowed lists of lists and the list processing symbol (\"|\") instead of just variable names in algorithms.  Equals4 worked with inversions (running predicates backwards).  Inversions may require the cut command after returning results.  I needed to compensate for variables such as _1, _2 in the results.
56.  I replaced findall with find n solutions and a variable to return if the user had run the cut command.  Using find n solutions was part of implementing findall with cut in the body in SSI.  I ran SSI's cut command.  This case required a particular verification file for SSI.  I modified findall in LPI to return results from each pass of the findall body one at a time.  If the interpreter had run the cut command during the pass, findall stopped.
57.  I automatically saved type statements with predicates.  I generated types for predicates. Then, I inspected the commands' type statements.  I generated the predicate's type statements, considering the type statements from other predicates.  I found instantiation and type errors.
58.  I predicted features from my texts.  I generated data from types.  After finding the type statements, I aimed to see whether the algorithms were correct.  I predicted features.  I predicted bug fixes and API changes (variables as A to  [v, a]).
59.  I found the exact data and type statements.  I checked whether the data was too specific. Then, I detected whether the type statements were too specific and could be simplified. Then, I worked out whether the algorithm was too specific or too complex. Finally, I saw whether the data was too specific for the type statements and whether the type statements could be made more precise.
60.  I chose solutions that led to more creativity and simplicity. First, I checked whether the data was wrong.  I did this by finding the correct data and algorithm from the specification.  Then, I detected conflicts when it was wrong.  I resolved these conflicts.
61.  I objected to undefined variables returning false positives.  I checked whether the data was too general.  I detected whether the type statements were too broad and could be made more specific.  I saw whether the algorithm was too general and had bugs.  I noticed whether the data was too wide for the type statements and whether the type statements could be made more general.
62.  I could make computer courses available as open problems.  I sped up mind reading and tested for sentiment, the existence of thoughts and thought-conversations.  I used random mind reading (which was faster) by activating it using mind reading CAW, which spent longer asking a few people about the characters of the day.  I used mind reading to make psychological predictions about whether a user would make changes to code.  I wrote the most intelligent conclusions down and sped up writing code with my brain.

63.  I could predict the change of order between lists of lists.  I started by changing the order of arguments from 123456789 to 321 654 987.  I did this by breaking 123456789 into 123, etc.  Then, I reversed 123 to 321.  I repeated this for the other lists.
64.  I stored the operations in a single place.  I started by writing an induction algorithm in C.  First, I gave it 1,1 and 2.  It worked out that 1+1=2.  It could apply this rule to other data.
65.  I could store trees as lists in arrays.  Storing these variables was part of writing an interpreter in C.  First, I parsed A=1+1.  Then, I calculated A=1+2=3.  I kept variables in an array.

66.  I wrote the parser with List Prolog grammars, which had more arguments and allowed recursion with variables (where there could be a cognitive string parser and an optimised version).  I used this technique to write a parser in C.  First, I found words and elements that I frequently found.  Second, I found frequent groupings of these. Finally, I discovered their recursive hierarchy.
67.  I used CAW to find a multiplication algorithm.  Earlier, I added multiplication to the register state machine.  I did this by using long multiplication.  The complexity of long multiplication was O(n^2).  I could also use other algorithms.
68.  I used an SSI algorithm to unify lists.  Unification followed passing list processing to the register state machine.  First, I found and passed the head and tail to variables.  Next, I processed them.  The variables contained lists.
69.  Lists could contain links to other lists.  In this, I assigned lists to variables in the register state machine.  Also, the list could be a list of numbers.  It could contain atoms and strings.  It could also be a list of lists.
70.  I added the ceiling function to the register state machine.  I read 4.53.  I found the upper of 4 and 5.  This equalled 5.  I found ceil(-4.53) = -4.
71.  I added the floor function to the register state machine.  I read 4.53.  I found the lower of 4 and 5.  This equalled 4.  I found floor(-4.53) = -5.
72.  I used the most accurate square root algorithm.  I added square root to the register state machine.  I found likely square roots between values and kept on increasing accuracy.  I stored them in an array.  I found other square roots in terms of them and bisecting.
73.  The computer could return long numbers or my philosophy.  I did this by adding powers to the register state machine.  I accomplished this by multiplying the number by itself n times.  I could use a fast algorithm.  It seemed better than a calculator.
74.  I could examine the number's format.  I added an absolute number function to the register state machine.  If the number was positive, I returned it.  If the number was negative, I returned -1*n.  I could tell whether the number was negative because n<0.
75.  I could find member(A, B) or member(1, B).  I found the member command in the register state machine.  I found member(A,[1,2,3]) returned A=1, etc.  Also member(4,[4,5,6]) returned true.  I found a member or whether the item was a member of the list.
76.  I inverted delete.  Before this, I deleted the item in the register state machine.  I did this by deleting all instances of an item from the list.  As part of this, I processed the lists from start to finish.  Then, I wrote the final list to memory.
77. Upon entering foldr(append,A,[],[1,2]), the interpreter returned A = [[1, 2]] and when I entered foldr(append,[[1],A],[],[1,2]), it returned A = [2]. I appended the list item in the register state machine.  I appended [1] to [2] giving [1,2].  I entered append(A,B,_), returning A = [], A = [_], A = [_, _], etc.  There were many modes, also in foldr append.
78.  I could invert mathematical functions.  I found the sum in the register state machine.  I entered foldr(+,[1,2,3],0,A), returning A=6.  I entered foldr(+,[1,2,3],A,6), returning A=0.  I entered foldr(+,A,0,6), returning A=[6].  
79.  I changed recursion to iteration.  I completed recursion with recursive findall.  In recursive findall, I didn't need complex base cases.  It was less complex than findall and recursion.  It was like iteration.
80.  I reordered arguments using properties of their item number, recursively. For example, I paired items 1,2 and 3,4, etc.  Or, I found every nth number.  Alternatively, I found every mth nth number.  This number equalled every m*nth number.
"]