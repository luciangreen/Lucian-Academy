["Green, L 2024, <i>Immortality 17</i>, Lucian Academy Press, Melbourne.","Green, L 2024",1,"Immortality 17 - I could help more people become immortal.

1. I noticed multiplicity and higher similar institutions. Like finance, people found out about immortality in time. They learned meditation and other courses in time to become immortal. Instead of on a pinhead, my life rested in a cup. I could build an institution, also with the help of Chinese herbs for longevity for energy and which helped me learn about longevity.
2. I first completed the meta-induction for an algorithm, then let neuronetworks join and modify the parts. I found ways of completing algorithms more quickly. Then, I increased the accuracy of neuronetworks by creating \"hands\" and \"bodies\", not blocks. I stayed with specific algorithm writers. Finally, I added a feature, a new algorithm writer.
3. I knew exactly what I wanted the neuronetwork to do, and it did it. It felt like the machine of neuronetworks was missing in our times. The human creations were black boxes, unable to be found out by machines. The machines could only examine existing knowledge. So it is vital to simulate wonder for the machines to produce science.  
4. I loved completing the algorithms and extending my knowledge. I aimed to increase small thoughts about immortality. Continuing from paragraph 3, I asked, were the scientists humans? The robots used humans' ideas to find new conclusions. By the end, the robots attributed humans with machine science, and the simulation was like an intelligent machine.
5. I used time travel,  which inspired my philosophy. Like the bible, I connected each chapter to each other chapter. These connections were how the brain worked. The religious people were the most developed because of \"n\". Separately, I decided to visit the other country.  
6. I taught philosophy and computer science. The people were very interested in immortality. The robot custodians highly desired it for the people. The immortals could keep going, and the universe continued. Because of the simulation, I could time travel and live in the universe, which continued anyway.
7. The writer child could write originally. The pregnant woman time travelled or replaced her body, and her unborn child became a bot. It needed increasing still, like a human child. Finally, the child was born safely with enough As. The budding or human replication expert gave enough specific As so the pregnancy went as smoothly as clockwork.
8. The writing was relevant and had a certain number of connections. I determined what was necessary for a planned child to become immortal. They needed originality, a number and spiritual and other topics. I turned over enough keywords. I kept algorithm specifications, which I connected to the topic.
9. I also checked that I had linked the paragraphs together. To complete copywriting, I used meta-induction, neuronetworks and a connections neuronetwork. Meta-induction determined algorithms from data a priori connections, not a posteriori. Neuronetworks found algorithms with commands that were too difficult for meta-induction to find. I paraphrased text on the writing side, then found connections with a connections neuronetwork.
10. I remembered that any complex code could and should be simplified. I found the meta-induction, also known as Program Finder with Types algorithm. It found pattern-matching algorithms with any reasonable extensions able to be added. There was a user interface program finder to create web scripting algorithms. I inserted the formula for the algorithm to use, and it searched with this to find any needed output, replacing part of the algorithm with this formula.
11. I allowed rendered code to either contain or not contain extra features based on compilation or runtime flags. I found what parts of the algorithm I could find with the meta-induction algorithm and gave the black box inputs and outputs in a text file to the neuronetwork. It quickly found combinations of past formulas. I could find these in the hierarchy of the logical structure of the algorithm or in another order. I started with a simple model algorithm and added more features, translation, garbage collection and optimisation, if necessary.
12. I broke neurofeatures into groups of groups and built them up from simple models. First, I wrote the exact logic for the neuronetwork algorithm. Then, I broke the specifications into steps. I started with a simple model using meta-induction. I refined work as I went, making optimisation easier at the end.
13. I wrote a \"head-iser\" to push list processing into the predicate head and a DFA minimiser to optimise the predicate. I did this by breaking features into groups of fewer variables. For example, I found equals4 in a few lines. This code translated well to C. I counted the reduced set of instructions.
14. I researched member check and using sort for unusual purposes. I wrote a \"head-iser\" to push list processing into the predicate head. I moved list processing into predicate calls. If it resolved better, I moved list processing into the head. I changed if-then clauses into different clauses of the predicate.
15. I separated commands into their different modes and implemented them in C. I researched member check. Member check is member with cut after it. I wrote another member predicate, which for example, checked 1 was a member of [1,2] (rather than giving the members of [1,2]), which had different modes from this second command, and was used for its purpose in combination algorithm writer. The program wouldn't work if data didn't match these commands' modes in CAW.
16. I wrote another predicate to remove duplicates without sorting. I used sort for unusual purposes. Sort sorted from smallest to largest and removed duplicates. sort([[2],[1,1]],A). returned A = [[1, 1], [2]]. and sort([[1],[1,1]],A). returned A = [[1], [1, 1]]. I used sort in decision tree creation, in particular unique item collation.
17. I used CAW or a neuronetwork, PFT and optimisation to optimise the predicate. I wrote the DFA minimiser to optimise the predicate. I removed duplicate clauses. I avoided if-then to avoid their appearance. I used recursion and other predicates, including itself, when necessary.
18. I wrote the exact logic for the connections neuronetwork algorithm. Instead, I tried the algorithm without the neuronetwork. First, I identified whether there was enough content in the sentence or whether I needed more context. Second, I identified the key ideas in the two sentences to be connected. Finally, I joined them using the required grammar.
19. I used a translation service that didn't run out of quota. I changed Cultural Translation Tool (CTT) to do all possible translations in one step. First, the page was back-translated, and the algorithm notified the user about sentences which back-translated differently. When these differences were passed or changed, the algorithm translated the next batch of modified sentences, and so on, until the algorithm had translated the document.
20. I added sentence splitting to CTT. If the user needed to break sentences to back-translate correctly, they entered them as separate sentences and were back-translated separately. If the user had previously changed a sentence successfully, it was changed. Split sentences were re-added to other documents to retranslate, or the user could use a particular possible sentence version. Also, I could rewrite documents and join sentences using text files, which were all saved from an earlier point.
21. I ran the translation past a native speaker familiar with the content to catch \"back-translation errors\". I added translation updates across languages to CTT. The algorithm tried all previous sentence versions to find a correct back-translation for a language. I dumped this idea in favour of preserving finished versions of documents. However, changes to the content or the need for uniformity meant the latest parts of documents could be merged and retranslated. The system meant updates to study materials, websites and marketing materials could be rapidly written and automatically made.
22. I could also translate code in CTT. I wrote this code in List Prolog, allowing for phrases and sentences as predicate and variable names.   CTT notified the user about data changes that would require changes to the algorithm, and it did these manually, triggering a warning if someone tried to overwrite them. But, again, bulk updates to content were possible otherwise, and I preferred staying as close as possible to a single document version. Occasionally, cultural, linguistic, and other reasons meant the user needed to save content separately. It was marked as such or stored in a separate folder (with a pointer) before documents were moved or changed.
23. The algorithm notified the user if the pointers to the unique parts of CTT documents were deleted or duplicated. The individual parts, counterparts in different languages, were stored together for easier editing. If necessary, the user could use a command to replace them with a single non-unique part. The program would back up each version. Unique parts could also contain pointers to other unique parts, and a command could merge them.
24. The quantum entanglement algorithm had 5*50 As for the answer to repeat. Separately, I wrote a duplicate content finder algorithm. To avoid duplication, it searched for content that was the same or very similar to other content. Also, content that was missing or incorrect was identified and fixed. An algorithm could identify incomplete sections and notify the writer or schedule updates by a specific date.
25. A format uniformity algorithm checked that capitalisations, spaces and quotes had the same format. Also, the CTT content that was missing was identified and fixed. For example, if the paragraph had a number but no content, it was flagged. The algorithm would copy the content from the original to it, and a person would check the result. If the document type was a term (and the algorithm needed to convert symbols such as brackets), the algorithm converted it to the correct format.
26. A favourite was a hierarchy of strings and algorithms within a string or algorithm, which were pretty-printed. Separately, CTT content that was incorrect was identified and fixed. If a repository had testing, update or other difficulties linked to the algorithm, it was queued and brought to light. Then the algorithm fixed this, and necessary changes to other code and CTT documents were made. The CTT documents needed to be translated and published.
27. An algorithm grammar checked the content before translation. The grammar checker was suited to computer science purposes. This algorithm ensured that the document to translate was perfectly grammatical. Also, it provided that the back-translation would be better and helped make the translation better and more straightforward. After all, the algorithm would translate grammatically simple expressions correctly.
28. The system and lecturers had to help mind map, correct and finish algorithmic breasonings with an A. The SSI Academy Site automatically marked essays for relevance, structure, grammar and breasoning count. The algorithm automated the financial site. Also, marketing came from the profits and helped the school remain open. Students received certificates and could display the course on their curriculum vitae as accredited.
29. It would be detrimental if students forgot their thoughts all the time. Also, the algorithm marked the essay for relevance. The algorithm checked the words, their order and synonyms in the paper. Without a citation, the algorithm would mark these phrases as plagiarism. Finally, the system helped provide spiritual suggestions and psychological support to the student while they wrote the essay.
30. There would be a meeting with a student progress officer if the student failed 50% of their courses. Next, the algorithm marked the essay for structure. The piece needed an introduction, exposition, critique, conclusion, references and citation style, all with the correct format. A traversal-checking algorithm checked for the argument structure and missing links or links between parts, such as paragraphs. An algorithm found differences in opinion from the texts and marked the essay down.
31. The algorithm was marked for grammar. The algorithm marked down errors such as missing or incorrect parts of speech, spelling errors or other grammatical errors. The algorithm identified fine details such as the word \"references\" not \"bibliography\", unnecessarily numbering references, too few references or using \"ibid p. x\" instead of \"ibid\" for the first reference after a reference with a page number. Corrections to these errors were found and presented to the student. The software could fix these errors at a premium.
32. The students could keep and publish their algorithms in a book or online. The algorithm marked the essay for the breasoning count. The number of proper breasonings (spiritually passing, good ideas and algorithmically logical) was counted and compared with the number required for a particular mark. It was best to tell people about the requirements so they knew what to work on and could find ways to support themselves to produce them. I became an oblate during Philosophy honours, which reminded me of the pedagogy text.
33. I'm sure I saw something like memberchk(65, `ABC`) somewhere. I devised a webpage unit testing algorithm that used the curl command to test whether an SSI Web Service algorithm was displaying correctly. It would already work in SSI (in the terminal), but if it produced the same results in SSI-WS, it passed. This algorithm traced the algorithm's output as the user entered a particular input. The program could fix errors by using previous versions or corrections to algorithms.
34. I developed a login system, simple word processor, content management system and sales funnel for SSI-WS. The advantages were that the program (including security features) was invisible to the user, and data to display could be processed by algorithms and displayed as part of the website. It was connected to email and files and made it easier to run Prolog algorithms, through the web browser. A low-code back-end allowed programming in the simple, intuitive,  clever and powerful programming language Prolog. I could develop a program development suite that taught and helped build web apps that connected free and customisable components.
35. State Saving Interpreter Web Service could run Prolog algorithms over multiple web pages and provide access to the simulated intelligence ability. For example, I could write computer games between people on two different computers with SSI-WS. The game required the users to log in and start playing a game together. It might be a word game, a timed puzzle or a decision tree adventure game. The server connected the users on their computers, a friendship could form, and the algorithm could save high scores.
36. I developed a Javascript scrolling list file system for SSI-WS. SSI-WS provided the back end for the system (access to files on the server from anywhere). Javascript provided the front end. I could implement the scrolling list file system in HTML using SSI-WS commands if needed. HTML could also produce colour pixel graphics for 2D or 3D platform games and accept single key presses using Javascript for control.
37. The computer was futuristic, like someone who knew you and your sensitivities and only suggested mentally nourishing activities. I developed a graphical operating system in Javascript for SSI-WS. I could also create this operating system in HTML, but Javascript provided mouse and interactive object support. It could be 3D, like a room in one's room or a fictional or realistic workplace or institution. Work could be automated, except for the human creative and cognitively correcting parts, of which the humans would learn the operations of the algorithms.
38. I used Java3D to create the 3D scene and interact with others. I developed a 3D web game that simulated an educational institution in SSI-WS. I could balance work with physical activity, such as walking, non-contact sports or gardening. I could plan and help correctly complete physical activities after working them out on the computer, with, for example, knowledge about the local wildlife and plants and the best way to start gardening. SSI-WS made making a text engine for the school simulation easy, and game/document exchange sides were possible, within reason.
39. Prolog could detail each screen and place characters and adventure instructions in the maze. I developed a text adventure game called Vetusia with graphics in SSI-WS. The first option was a text adventure with a compass and up-and-down directions to travel through the maze. The second option was static, hand-retouched graphics for each screen and clicking on the directions on the image. The third option was a 3D animation of moving through the Vetusian site, with gaming friends and chatbots.
40. Vedic astrology opened up the unknown and offered a seen-as version to support finance. I wrote Vedic Mind Reading (VMR) software that found the auspicious dates and times for a company opening or launch, which increased the quality of mind reading results in Music Composer or Grammar Logic. This Jyotish (Vedic astrology) algorithm's results were also helpful in finance because it anticipated the best stocks to buy without insider knowledge. As a result, people could sell before crashes and buy safer commodities. The money would stay in the country, and it could compensate for values going down.
41. People could now work overseas with their qualifications. I foresaw governments accepting international university degrees worldwide. Other countries would take a country's university degrees. This development may mean an educational institution may be able to be established overseas by someone from the first country. This acceptance was akin to time travel and peace spreading through time.
42. The educational institution could open its doors to international students without paying full fees. I predicted accreditation becoming international and governments giving students loans for international degrees. I wondered about regionally differing prices. I noticed some forms of international certification and wondered about government funding. The institution could stay there and suggest many thoughts, including algorithms.
43. With the advantages of paragraphs 41 and 42, I could live in the country of my choice with a pension and open educational institutions that could have students anywhere in the world. I developed the course. I wrote a book accompanying it to explain it to children. I noticed children's school objects and ways of thinking (such as the ethics of an issue) and connected the books to them. The children were genuinely interested in adult works but lacked some skills, not knowledge, to do certain things.
44. I wrote all the arguments and algorithms required for a first-class degree. I knew the time needed to produce a degree for an educational institution. The first degree offered was interdisciplinary, a conjunction of philosophy books. Each degree required (3-4)*4*50 As, and these arguments and (some) algorithms could be written (in the same time as, not while) the degree was being studied part-time. I also recommended the vocational business diploma and Education master's degree.
45. I sowed the seeds of life for my business, starting when people were grown up. I could add to any of my philosophies, and the algorithms would follow. The \"N\" factor meant that the algorithm needed documents of a certain length. The nature of these reports remained internal. They were often divertissements (perspectives on topics).
46. I wrote the symbols movie. It featured the generated music and was dot-to-dot bitmap stills or voxel animation-based. I wrote the philosophy. I wrote the algorithm and converted it to a movie. It was interactive, and users could zoom into movies about each algorithm. There were similar symbols depicting each algorithm, and as users watched a movie, the programmer included them in the algorithms.
47. I worked out how much to invest and how much to write to start an institution. I planned my finances, allowing for government funding and customers for my business. I bought accreditation for my educational institution. I generated and provided courses in different languages. I could write lessons for programming languages, such as mathematical manipulation, art generation, web graphics user interface or non-deterministic languages
48. I wrote a mathematical manipulation language. Its results were mind-read and helped users stay mentally agile and think critically about objects, courses and algorithms around them. They calculated and checked the properties of ideas in classes. And they found optimisations and simplifications of algorithms. An algorithm could ask preliminary and \"à présent\" questions about more complex algorithms.
49. I wrote an art generation language. It could generate dot-to-dot bit map images in colour. These images included graphs with planes or regions. Or it could produce music, which helped them mentally prepare for implying imagery properly. They could mind-read new sections of songs by learning to compose the music mentally.
50. The language could display bitmap, 3D or layered graphics, and students learned the language for assignments. I wrote a language for a web graphic user interface. This language had different metaphors, such as duckling house, musician's studio or meeting friends. Users could befriend the ducklings, and the musical software could be hand-written for individuals' needs and effects, such as writing on top of or recording lateral thoughts were possible. People wanted to keep memories, so these were made into accessible documents and printed out.

51. I wrote a non-deterministic language. It finds programs within programs (i.e. state machines). I saw the circle. It was a time-dependent set of data transformations. I found list transformations, including list decomposition and building, and associations or variables needed in other algorithm parts.
52. The language could contact people and take care of products. I wrote a commerce report-generating language. I collected the data. I generated the report. I wrote an algorithm that drew graphs, made recommendations, put ads up and took care of the business's finances with approval from a person.
53. I also kept the character recognition algorithms in one place, for use by, for example, the text to breasoning algorithm, with modifications such as no \"'\" if necessary. I preserved formatting by processing n and m dashes in the paraphraser algorithm. I detected the punctuation or space. It was separated if it wasn't an alphabetic character in English or another language, and the algorithm only replaced words. Students should start their breasoning dictionary, thesaurus and algorithm database from scratch to deserve their marks.
54. I considered putting the package manager online, with download links to the host, and snapshots of stable versions of repositories. First, I had one repository for user data and one for reused predicates. Several repositories used the user data repository, which made it necessary to have separate copies of these repositories in another folder. These could be modified and updated at leisure. Users only needed to install the relevant repositories.
55. I modified the Essay Helper documentation to explain the essay format, possibly write specific comments, and encourage contacting subject coordinators to check whether the software is allowed for a course. I explained the software arbitrarily chooses sentences with the keywords, including unrelated grammar and formatting, and to review and paraphrase the text before submission. Also, users needed to check the sources produced by the sheet feeder and poorly formatted or badly converted text removed. Another algorithm could detect incorrectly converted text from columns. Or, one could detect gibberish from OCR.
56. I programmed the gem with spiritual algorithms such as text to breasonings, grammar logic and mind reader, timing different gems with different tasks (mind reading the input and output, using the spiritual computational ability of the stone). I pretended that a crystal (like a computer) could remind me to do testing. With A, a crystal could represent any algorithm. It could run algorithms and process data. Like cosmology had a class of algorithms that found program finders, new options to call them (and the accompanying documentation), and commercially viable versions of algorithms, users could program gems like a computer, for checking, lecturers to detect and do work, for home security, for helping one's physiology feel developed, for better spiritual presentations and reminders and reminders to make reminders, all with Prolog algorithms.
57. I researched computation-compatible gems and connected them. I taught the (meditation helping) gem to recognise and use saved commands. I hypothesised that kunzite could help make connections between members of a class, amethyst helped with security, testing and correcting code, fluorite ran regression tests and transformations in the background, turquoise ran text to breasonings and other spiritual algorithms, yellow topaz could run different algorithms or an operating system, rhodochrosite ahead of time detected and corrected unwanted changes to the heart rate, circulation, blood pressure, the kidneys and reproductive organs and prevented skin disorders, migraines, thyroid imbalances and intestinal problems, while restoring bad eyesight and cleaning the circulatory system. In contrast, azurite helped one find enlightenment by finding new connections to new ideas, songs, algorithms and art. I could simulate the microprocessor. In this way, I could support the text to breasonings algorithm by processing human knowledge passing through the microprocessor.
58. I also recorded what the text to breasonings algorithm could do.    I breasoned out what the gem needed to do to program it. The time crystal, simulated on a computer, enabled a system to loop in time. I could program a house and lawn simulation, mind reading the attributes of objects the gem represents. I programmed the objects in the simulation in the gem to time travel, where the state machine helped the body to live forever.
59. I conjectured that the crystal could play spiritual sound effects and help with medicine. I programmed the gem to display a spiritual screen to help visualise data. The Gem programming language could project 4*50 As for frames of a decision tree, controlled with 4*50 As (where the controllers needed to be fast quantum box breasonings repetitions). It helped differentiate ideas and display colourful imagery. I ensured my Prolog interpreter didn't skip or optimise verification steps necessary for running text to breasonings.
60. The crystal algorithm reviewed the logic of thoughts, reminded of forgotten ideas, checked thoughts against the trajectory statement and sketched out the future endpoint. The crystal could change tree-structure stories into cycle-containing philosophies and algorithms. Text to breasonings, etc., were supported by a single crystal owned by the meditation teacher, which interfaced with the future, contained practicums and displayed imagery and reinforced results. Someone in another dimension performed all the computations simultaneously, and the developed thing was the crystal performing. Someone activated the future window that supported text to breasonings for breasoners in our time, and the company wrote As so that crystals made thoughts clear and logical.
61. I experimented with different programming languages for various crystals, such as database, maths, algorithm or logic formula finders, using developed data for data that resonate with the crystal. I computed 1+1=2 with the crystal by storing the input and algorithm in a spiritual container associated with the crystal with 4*50 As with text to breasonings, running the Prolog algorithm with 4*50 As per command, mind reading the container for the correct output with an open terminal window, trying again until reaching the quota of tries and displaying the answer on the computer screen. The algorithm helps with lucianpl and SSI by comparing their output with LPI output. The crystal vibrated at different frequencies for specific Prolog commands. I could write programs with commands with frequencies compatible with the crystal's chemical structure.
62. Equipment could detect waves emitted by the crystal. I used a form of mind reading to check what languages, algorithms, data types and types of data (such as music) resonated with a crystal (I could also check compatible resonance frequencies of objects). I found the resonance frequency of the crystal, vibrated it or not, signifying 0 or 1, and ran any algorithm with this frequency. The algorithm represented choice points, data, etc., by human-controlled timing. I researched computers and other technology using crystals.
63. The crystal was used when needed and was placed in the right place in the room and house. I tested whether pictures and specific questions enabled better mind reading. I helped students spiritually with their questions and answers. If they didn't have a question, I made one up if they needed help. I mapped crystal frequencies to different words to point things out to people.
64. I could design a spiritual computer to program if I could improve projection and mind-reading quality. I bought the channelling crystal for improved mind reading. It helped me find the best answers, such as mind-reading myself when wanting to work but not working. Other algorithms could help complete work at these times. Using additional algorithms, I could enter the correct changes and corrections to this output, and it made them automatically.
65. My spatial reasoning improved. I breasoned out 4*50 As, with which the crystal more effectively turned headaches off. Imagery appeared more clearly. Thoughts about objects, people and settings were clearer. I aimed to write 2-4*4*50 As in Physics to win prizes.
66. I wrote the algorithm to work out where I was. I improved my spatial visualisation capability. I made a model. I wrote the formula for its attributes. I worked out how to do this in my mind with the help of a co-worker.
67. I reduced the time needed to write an algorithm. I used crystals to mind-read whole algorithms. I wrote algorithm writing algorithms and entered the specifications with the computer keyboard. The algorithm worked out as much as possible without unpredictable commands, displaying and saving its progress. I entered and then wrote an algorithm to work out the missing steps, whether single or multiple commands or these within recursion or involving random numbers, APIs, files, input or mind reading.
68. I wrote algorithm writers for each algorithm I had written, using identifiers of a part which is an algorithm, analysers for how they connected and ontologies for putting them together in new ways, and ideas about when this would be necessary. In addition, I could automate writing algorithms containing algorithms, state machines, structured data in strings, multiple levels of this, different methods, and different spoken/programming languages or graphics. I collected and grouped methods from my algorithms. I used findall, forall, findnsols, etc. I created specific commands, editors and debuggers.
69. I questioned whether the behaviour of crystals could be captured and simulated on a computer, for example, with enough As. I analysed crystals' quantum box properties, including those for medicine. Instead of breasoning something by itself, I breasoned it by the crystal. I tested whether concentration, comfort, relaxation, thought quality and types of thoughts were different from using the crystal by itself. I did this for each crystal and for placebo crystals that weren't present.
70. I expanded what I knew into what I didn't know. At any rate, I gave As to crystals I didn't own, to answer questions for others with text to breasonings and to Chinese herbs I didn't take. I designed a simulation of my life in Prolog to capture and do things I couldn't do myself, but could read then, which involved mind reading, research and perfect breasonings. I gathered knowledge about the people, places and conclusions I wanted, and my dreams came true. I became interested in different ideas, even unusual ones, to help me help others help me, and defined my views about my choices about them.
71. I found stones' resonating books, chapters and algorithms. I used the Grammar-Logic algorithm with one algorithm per spiritual stone to help mindmap ideas. I methodically found ideas for different algorithms with each stone, comparing the same algorithms with other stones to see the different results. I found the types of algorithms suited to a stone with mind reading. I imagined testing the frequencies of an algorithm (in its simplest textual form) and a stone and seeing if they matched.
72. I detected the kind of algorithms a crystal pointed to about a philosophy. I collected and helped define philosophies and algorithms and presented the seen-as version of philosophies and algorithms written with the help of the crystal. I also used crystal mind reading with Essay Helper to make customisation choices, such as synonyms, synonyms for \"also\", editing grammar, performing grammatical touch-ups, and following finding the context for a sentence or whether two sentences have anything in common. I found the right crystal for the point in the essay and detailed the text. Finally, I did this with \"detail\" algorithms.
73. One part of the Essay Helper algorithm checked that the total string length of the strings to form a decision tree was not over 250 characters. I did this as I went, not in one go, to stop the algorithm from crashing. This bug fix enabled longer files to be detailedly mind-read in Essay Helper. I wrote a language describing essay formats for Essay Helper using list types and variables. In effect, the language generated the algorithm.
74. I used an algorithm to determine the right recursive grammar. I added strings and files to the program finder with types algorithm. So far, the program constructs programs from list data. Strings could contain lists of characters/words. Files could contain strings or lists.
75. I spell-checked the sentence and then grammar-checked it, regardless of the grammar. I wrote a grammar-checking algorithm using grammar. First, it found the grammar of the sentence using parts of speech. If it couldn't determine the grammar or parts of speech used, it skipped the sentence, with a warning. Next, it looked for common errors, such as grammar, part of speech or agreement errors.
76. The grammar checker was primed for computer science. I checked the document's grammar for consistency, format readability, and overall content. It is essential to let the person develop the first draft of the paper and suggest optional changes to it. A page was readable if the main point was at the top and if it was on one page, the same page as where it should be. The algorithm took the document's content from data, which should be relevant, current and valuable to the readers.
77. An algorithm could test whether the text had the quality of a back-translation. I used an algorithm to check if someone had used the Cultural Translation Tool (CTT). This algorithm didn't involve using CTT again. When a user used CTT, the translation was accurate, the grammar used universal language (at least, that common to the two languages), and it was sometimes recognisable by the language being common to the two languages. If the language used the exact words or grammatical constructs as a language, CTT might have produced it.
78. Some cultures (not just countries or language speakers) might have specific taboos or cultural understandings of texts. Back-translation always seems necessary to check that a text is understandable using an intersection of languages worldwide. It simplifies, speaks in a universal tongue and makes writing procedural. It might require the simplest possible, meaningful grammar and use of words that must be recognisable for safety and other reasons. Trees of related languages might point to words and grammars a text should use before back-translation.
79. I used an algorithm to check if a user had used the Program Finder with Types (PFT). In the first version of PFT, data to algorithm found [d,[c]] from [a,b], [b,[a]] and [c,d]. The second version found algorithms with recursion, given data in repeated list format. The first version didn't deal with repeats such as [1,2,1,2] given [1,2], and the second version didn't find algorithms needing data passed from non-expected parts of the data. The second version can do what the first version can't, and the upcoming third version can do what the second version can't do.
80. The third version of PFT brings associated data to other places in the algorithm, and the fourth version addresses the problem of unpredictable commands. The third version finds the order in which the lists are built and works backwards to decompose lists to reuse data structures that recur. The fourth version looks for patterns in the data, such as sort, delete, out-of-order append and dependencies on member, length or string length or string concat. There may also be up-case or down-case, splitting, custom splitting or verification of character type. To check that a user had used PFT, I would use the algorithm to check whether a user had not made the specific optimisations not produced by PFT or whether the code was more precise. In contrast, the opposite, human-written code, would be more likely to be left in unminimised code.
"]