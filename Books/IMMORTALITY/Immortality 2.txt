["Green, L 2022, <i>Immortality 2</i>, Lucian Academy Press, Melbourne.","Green, L 2022",1,"Immortality 2

1.  I asked how much the students liked the algorithm or how easy they thought it was.  I asked the students if they knew the algorithm. Third, I asked them how many times they had used it. Finally, I asked them if they could work it out for themselves.  I timed them doing this without cheating.
2.  I gave the lowest (winning) score for the best-performing code.  To do this, I assessed the students in a programming competition.  In this way, I timed them, finding patterns in the input and output.  I also timed them in simplifying the code.  I gave the best score for the fastest, not most straightforward code.
3.  I listed the skills needed for the project, finding appropriate methods using mind reading.  I noticed the string to list algorithm required lookahead.  I found the reason for mastery, in other words, the way to work them out.  I worked out whether this way was likely to be encountered.  I marked assignments fairly, giving more marks for more straightforward test cases.
4.  Also, nested findall could produce lists of lists.  I checked whether findall was appropriate.  I used findall when processing, analysing or verifying a list or series of lists.  I took the input [a1,a2,...,an].  I produced the output [f(a1),f(a2),...,f(an)].
5. If desired, findall could produce [], effectively deleting an item in the list.  I used nested findall to produce lists of lists.  For example, [[n,findall],[[v,b1],[[[n,member],[[v,a1],[v,a]]],[[n,findall],[[v,a2],[[[n,member],[[v,a2],[v,a1]]],[[n,equals4],[[v,a2],1]]],[v,b1]]]],[v,b]]]	.  Nested findall could process lists of lists, outputting lists of lists.  For example, it took the input [[a11,a1n],[a21,a2n],...,[an1,ann]] and produced the output [[f(a11),f(a1n)],[f(a21),f(a2n)],...,[f(an1),f(ann)]].
6.  I saw what percentage of the philosophy was non-computational.  I processed the list with findall.  In this, findall produced a list, not an appended list or a string.  Findall couldn't analyse the previously inputted or outputted lists.  I used it to produce a list of lists, which could be flattened and concatenated as a string.
7.  Later, I could sum the list using a predicate. Finally, I analysed the list using findall. Then, I calculated a mathematical function with each item.  For example, given [1,2], I figured A is B+1.  This computation resulted in [2,3].
8.  I found the position number by creating a list from 1 to the length of the list and selecting using a get item n predicate. Then, I verified the list using findall. Next, I checked whether each item equalled its position number + 1.  For example, I was given [2,3]. Then, I checked that the first item = 1+1, etc.
9.  I summed the length of each file.  I counted the values in the list using findall. Next, I found the string length of each item.  The program used string length to count the number of characters in each file line.  I summed the frequencies.
10. I processed the list of lists with findall, possibly followed by list subtraction.  I listed lists with a certain item.  For example, I was given the list of lists [[a,b,c],[a,d,e],[f,g,h]].  I only wanted lists with a.  So, I returned [[a,b,c],[a,d,e]].
11.  I analysed the list using findall and then plotted the graph on the screen.  I summed the list items and found the gradient of the resulting graph.  I gave the input [[1,2],[3,4]].  I found the sums [3,7].  Assuming x = position number, I found the gradient (7-3)/(2-1) = 4 (very steep).
12.  I verified the property of the list of lists with findall, followed by checking that only empty lists were returned.  I verified that the list of lists contained no instances of an item.  I gave the input [[1,2],[3,4]].  I checked that each list didn't contain 6.  I produced the result [[],[]].
13.  I counted (found the length of each list of lists) with findall, where nested findall wasn't needed but could be used to return lists of lists.  I was given [[4,5,\"a\",*],[_],[]].  I returned [4,1,0].  I could separate functions into different functions.  I could distil out an item and then count the items.
14.  I found outliers in the data with a predicate, not foldr.  I used foldr (which took [a,b,c] and produced \"abc\" or took [[a],[b],[c]] and produced [a,b,c], depending on the additionally supplied function name).  Foldr was usually used to append lists or concatenate strings, not for simple findall tasks or more complex tasks that needed access to previous input and output.  I always checked whether I should use foldr or findall before considering predicates.  I could use findall with foldr but not vice-versa.
15.  I used nested foldr (with foldr in another function) with lists of lists.  I used a predicate when findall and foldr were inappropriate.  I repeatedly added or deleted items in a list.  Separately, I used foldr when possible to process items.  Foldr eliminated many list processing and append statements.
16.  I also avoided foldr with a predicate because it was too complex.  I used foldr with a predicate.  I used foldr to change [a,b,c] to (a:b):c.  I avoided referring to other predicates too much to follow the algorithm easily.  I could expand the code that used \":\" and replace it with \"-\".

17.  I examined and explained the little interesting things about the skills from the later drafts.  I did this by writing the skill hierarchy for the task.  To do this, I first wrote the task.  Second, I broke it down into steps or an algorithm. Finally, I examined the skills needed and the changes over drafts.
18.  I accredited my organisation and helped others with professional development.  I did this by helping consolidate the skills.  To do this, I strengthened the skill for the student's career. Next, I revised the skill with the student. Lastly, I helped the student to test themselves regularly.
19.  I tested the skills the student knew and their knowledge gap or what they didn't know and helped them regularly revise their weaknesses.  I tried for the skill in the assignment.  The pass mark was 100%.  They repeated it until they passed.  I asked them what they did and didn't know.
20.  I put content in the lecture to customise it for the students.  I did this to address the skill deficit.  I attempted this by mentioning the content to the student.  Also, I managed small groups or tutorials. Then, an algorithm traced skills used in real-time, which the students used.
21.  I noted what the student needed help with.  I recorded the student's best attempt.  The student read the question.  They attempted it to the best of their abilities, noting what they knew and didn't know.  I helped them during office hours.
22.  I suggested that the students use books and sources and make citations when attempting a question, increasing their performance.  First, I noted the question.  Second, I checked whether the authority was relevant.  In addition, I checked that the student had followed it correctly. Finally, I indicated whether they had made necessary changes to the model answer.
23.  The lecturer noticed slight changes in the student's performance.  The tutor helped the student with their specific question.  They did this by guiding them with their attempted answer.  They didn't tell them the whole answer.  They just helped with the answer.
24.  The student made their philosophy index and wrote their chapter.  The student did this to revise for the test.  First, they made notes during the lectures and a summary.  They changed these regularly.  They attempted and saw the lecturer about sample tests.
25.  The lecturer aimed to help the students during their careers.  The student had different skills from other students and different interests during their careers.  The software worked by testing for skills in a formative (non-assessable) way.  It recorded progress in learning skills.  The student used it regularly to improve retention of knowledge.  Some argued for understanding rather than memory.
26.  I checked whether the new skills were better.  The new skills are related to the old skills.  Given this, I connected the new skills to the old skills.  I checked if these skills connected and then joined them.  If not, I replaced the old skills.
27.  The algorithm emphasised understanding the correct rule to use.  I noted that the skills were different from each other.  The skill applies a particular command to a problem.  It depended on the data.  For example, skills changed when the data changed, and could be collected for the same group of data, etc.  
28.  I helped develop the neuronal network by explaining the idea as a simple algorithm, with all variables labelled and defined.  I summarised the zone of proximal development to assist with missing skills.  I grouped the students by lack of knowledge in an area.  The students learned with other students who hadn't understood an area.  I realised that the student might have a disability and needed help building neuronal networks.
29. I found that the training in fast programming taught the same skills.  At first, I noticed that skills were different for different people. For example, one person attempted a problem with one algorithm while another used another.  This phenomenon was true in computer science.  I wrote the algorithm as a function call, automatically inserting cuts to optimise tail recursion.
30.  I looked for a match between the skills I needed in employees and what they had.  I examined how people with different backgrounds and experiences had other talents.  I predicted their skills from their knowledge and expertise.  For example, I knew that the project they had worked on required specific skills.  I saw the kind of trajectory of skill-building they had and worked out what they could learn.
31.  The neural network could sometimes correct the simple error.  The skill was different from the skills I had covered before.  I used the same skills but wrote more and more sophisticated algorithms. For example, I evolved from a program finder with types to neural networks.  I worked out how to use a program finder with types to do what only CAW could do, for example, recognise a number with many decimal places, which might result from a mathematical function.
32.  I used a program finder with types instead of CAW to detect dependent variables and run, e.g. foldr, findall or a predicate.  I charted different methods used for similar problems over time.  I redrafted the solution using these better methods.  With another algorithm, given a correct List Prolog Interpreter trace, I could detect where a State Saving Interpreter trace differed, find unwanted failures of commands, and possibly find the needed change using CAW and the previous correct function of the code.

33.  I renamed the variable to be used, inserted \"_\" before its name to turn off a singleton warning or renamed another variable.  I debugged the singleton.  I found the single, undefined and unused variable in the clause.  There was no way for its value to be defined, so it was useless.  Any reference to it (i.e. printing \"_\") was pointless, so it was a mistake.
34.  The algorithm or data might be in term form.  I debugged the operator expected error.  It was, in fact, a poorly formed term error because it might mean \"]\" or a term is missing.  I examined the correct grammatical structure of the term.  I added the valid symbol to correct the incorrect format.
35.  I corrected close misspellings or poorly named entities.  I did this by debugging the misspelled name in the algorithm.  I kept in mind that it might be a predicate name.  Or it might be a variable name.  I also looked for errors in the algorithm, for example missing \".\" or two \"|\"s.
36.  I debugged the use of the wrong command, where I also tried simplifying the data and command.  I compared the type of data given as input to the command. Then, I changed the command to take this input.  All the data depended on the type.  Or a part of the data depended on the type.
37.  I ran the correcter before compilation.  I debugged the missing command.  For example, I inserted the missing command flatten.  I saw the \"atomic expected, list given error\".  I inserted flatten to make the list into a series of atoms, etc.
38.  I tested all repositories and warned users that repositories had an old version number.  I debugged the wrong order of arguments in conversions.  For example, I noticed that convert(A, B) should be convert(B, A), so I changed it.  If I frequently used conversions using more than one command, I put them in one predicate.  For example, I changed commands to accept file names as strings.
39.  I debugged the missing input and (on an unrelated note) converted generative art with 5*50 As to an illustration.  I saw that the input given to the program was incomplete.  I completed the grammar for the input.  I completed the input to match the grammar.  I completed the input to match my meaning with mind reading or typing it in.
40.  I changed the command or the data to match the other's type.  I debugged the wrong types.  I listed the types number, string, atom, list, compound and undefined.  On a wrong type given to a command, I aborted with a wrong type error.  There was also a type statement mismatch error and a type of types (such as music) mismatch error.
41.  The computer generally avoided instantiation errors because it was on the correct path as it wrote the algorithm.  I debugged the instantiation error.  I found the instantiation error, where the algorithm gave an undefined variable to a command which required a defined variable.  I inserted input, another connective (set of) commands or changed the variable names to fix the error.  In the worst case, I entered the fix myself.
42.  I considered a predicate for processing lists simultaneously instead of findall.  I debugged the missing numbers//4 predicate.  I noted where an algorithm processed two lists simultaneously in findall.  Processing these lists didn't refer to finding all combinations of elements from each list.  I inserted numbers(N,1,[],List) to produce a list [1,2,...,N] and used get_item_n to get the Nth list item in findall.
43.  I deleted unnecessary include statements and duplicated included files.  To do this, I debugged the missing \"include\" statement and any missing predicates. Then, I found the name of the missing predicate. Third, I found the file containing the predicate.  I included it.
44.  I stored the global variables in a single variable to monitor them.  I debugged the unreset global variable.  I found the used global (asserted) variable wasn't reset at the start.  Neither was it reset if it was undefined, necessarily.  Alternatively, I set the variable's value just before the first use.
45.  I didn't reset variables in the interpreter call command.  I debugged the unwantedly reset global variable.  I found the algorithm that ran the algorithm unwantedly resetting the global variable each time it ran.  I changed the algorithm to reset it only if it was undefined.  On a separate note, I reset global variables if I needed to.
46.  I noticed that the variable was available in the level above, so I alerted the programmer.  I debugged, forgetting to get the value of a variable.  I found the undefined variable.  I found the value in the data.  I found a way to find the value or a new way to identify the value, for example, with a variable name.
47.  I deleted the unused variable.  I debugged, forgetting the global variable.  It was either not loaded or, in another case, the program loaded a local variable from the wrong source.  I attended to both of these cases. First, I diverged the global variables, for example, the number of items and the items. Second, I converged the global variables, for instance, XML-style tags, to name the variables.
48.  I saw the perspectival value of the variable.  On a separate note, I debugged not saving a variable.  I noticed that I had not saved the variable because it had been transformed or inputted from the user input or disk.  I detected not saving it with an algorithm.  I saved it.

49. I quickly found a simple algorithm without a database. I did this by making CAW faster by continually trying algorithms with Prolog, not List Prolog. First, I wrote the trial algorithm. Then, I ran it to see if it fit the spec. I repeated this until I found an algorithm that matched the specification. Finally, I used the call command to run the algorithms.
50. I checked that running CAW with Prolog was faster than using List Prolog, favouring Prolog. First, I timed List Prolog. Next, I time Prolog. Then I subtracted their difference. Finally, I multiplied this value to a more significant number given the number of tries.
51. Alternatively, I wrote a Prolog interpreter in C that could call an algorithm as an argument. I started by discovering disk optimisation. I  did this by saving the Prolog algorithm to disk. Then, I loaded it and repeated this many times. Disk optimisation kept the whole thing in memory if no other algorithms were accessing the disk, speeding it up.
52. I made it a priority to fix bugs. First, I corrected the bug and sold the software. I started by testing the feature. I continued by trying the software with all combinations of other features. I did this recursively with a depth of three levels.
53. I programmed the computer player smarter by guessing main, not unprofitable, letters in words. I started by programming the game with a computer player. At first, I gave the computer player rules to make a move. I made this fair for both players. Programming the computer player helped sharpen my skills.
54. I read to maintain my vocabulary. I increased my skill. I checked that I was as good as the computer player. Then, I memorised the list of words. Then, I ranked the moves to find the best one.
55. My sort of automation appeared human by keeping to a plan of ranking and eliminating the most significant choice points. I programmed the two computer players. I thought they were lucky at the start. I noticed the more advanced player guessed the word based on the writer's background. I relied on the rules initially and then took over when it started.
56. I tracked the player's competence using mind reading and how they were thinking by their Jyotish (Indian horoscope) developed things. I increased the opponents' skill levels. I noticed that the opponent occasionally took the risk of making specific guesses. I based these guesses on past words' choices, background, and words. I saw the player cheekily guess letters that intertwined with thoughts.
57. I sold the software, which was stable. It was an education about how to create software. First, I found the market trends (supplying needed features on a tried platform). Then, I conducted market research (wrote better features than competitors). \"Selling\" was the use of the software.
58. People learned how to use the software, considering their goals and career aims. To help with the software, I provided documentation. I also provided examples. As a result, people had specific questions. They prevented plagiarism.
59. I made the software proprietary, with explicit and suitable materials. To accomplish this, I wrote more tests, including applications using the software. To do this, I converted my applications into the interpreter's programming language. Next, I ran the tests. Finally, I back-translated the applications to test the converters.
60. I spent time talking with possible users and conducting research. This research helped when adding more features to the software. I did this by examining what was possible. Then, I added features. I kept things simple.
61. I noticed that the container's hard disk was in memory. Before this, I presented the software on a report web page. I inputted the algorithm. I converted it to List Prolog. Finally, I installed the software and ran tests on the web.
62. The project aimed to pattern match and concatenate strings. I gave marks for correctness. I generated more extensive tests using initial tests by substituting different components. I replaced 2.0 with 2 to see if the answer was different or correct. I appreciated the aims of the project.
63. Students could return to their work, which the algorithm saved to disk, and could save their progress. I designed the student area in SSI. It contained links to courses, enrolments and FAQs. There was a progress bar through studies, where course questions were critical analysis or computer science predicates. I tested for plagiarism, requiring resubmission of work was more than 80%
 copied.
64. The teacher described the use of Prolog and discussed the philosophy. I helped by compiling the FAQ about the assignment. It contained pointers to lectures about required syntax. In addition, it included details about the use of the student software. Finally, I noted that students could talk to the class, teacher and others using Prolog.

65. I could run List Prolog (a sped-up version) in Combination Algorithm Writer and generate algorithms.  I did this by writing List Prolog Interpreter. Then, I progressed by processing the body of the predicate. Then, I processed the recursive call. Finally, I checked the arguments in the call.
66. I could run web applications and develop online. I wrote SSI.  I found that the open-source software helped teach programming.  I handled choice points manually by storing and returning to them.  I worked out all the list members and found them all using findall.
67. I ran Prolog (for simplicity) with List Prolog Interpreter (to explore and add features to the interpreter).  I wrote the Prolog to List Prolog converter.  I used a grammar to convert from Prolog instead of list processing because Prolog wasn't in list form. First, I processed the predicate heads. Then, I processed the predicate bodies, including the data in list form.  
68. After generating the Prolog code, I could read it more quickly and print it in a pretty format.  I wrote the List Prolog to Prolog converter.  I converted the line of List Prolog to Prolog in the trace. List Prolog contained tokens to parse and run algorithms more quickly and could run \"internal\" commands.  I processed the algorithm as a list, concatenating the Prolog algorithm as a string.
69. The children were helped in school, and algorithms were logically suggested more easily than combophil (which suggested whole philosophies).  I wrote the Grammar Logic algorithm.  The Grammar Logic algorithm found topical keywords captured in sentence format, written as algorithms.  Combined with the mind reader algorithm, it prompted thought and helped with writing.  It seemed relevant and exciting to connect to the argument.
70. I wrote the Time Machine algorithm after years of planning.  I wrote a video about the Time Machine algorithm, text to breasoning, headache prevention and immortality. Time Machine helped people time travel with meditation and see the people from the future but not the setting or other details.  It worked because of breasoning out 250 breasonings for time travel, where breasonings required human preparation and writing.  The institution looked well on time travel and possibly prevented medical problems.
71. I noticed the bots could have the same as Text to Breasonings, enabling a variety of uses, including earning a high distinction, helping with business, jobs and children, mind reading, time travel, quantum energy production and particular medical benefits.  I wrote the Text to Breasonings algorithm.  Text to Breasonings converted a text to the dimensions of objects mentioned, helping with spiritual conclusions, such as earning a high distinction.  It used medicine writing to ensure that it worked.  It asked for new and breasoned out (thought of the dimensions of objects and letters) previous breasonings, funnelling some words into the same objects.
72. Obviously, I couldn't write and test an algorithm without writing the base case first. So I wrote the Combination Algorithm Writer Multiple Predicates (CAWMP) algorithm.  The algorithm repeatedly tried new algorithms (combinations of commands) until it found a match with the specification.  It produced algorithms with multiple predicates by starting with base cases and building up algorithms. In addition, it allowed numerous predicates with the same name as previous predicates, different names, etc.
73. I wrote the Essay Helper algorithm, which included critical thinking and business algorithms.  I designed the algorithm to plan the layout of the essay.  I helped write the critical evaluation essay.  The algorithm instantly generated the article (but it needed paraphrasing).  The algorithm could develop a whole PhD.
74. I minimised the state machine to avoid bugs and allow easier editing.  I wrote the LuciansHand BitMap Font algorithm.  The algorithm generated a font from dot-to-dot images.  It used a state machine to transition between pen up and pen down modes.  A graphing algorithm prevented gaps in lines with gradients greater than one (steep).
75. I planned the lucianpl compiler, which was a research project.  It was SSI, converted into C.  To prepare for this, I finished the converters. Then, I wrote more commands for the interpreter. Finally, I tested it Prolog, without choice points, before converting to C.
76. I could mind read myself to program names in algorithms. I did this by writing the mindreader algorithm.  Mind reader was hazy, a generative art algorithm.  Using it, I could generate music and art.  I timed how long a breasoning took to breason out, where a shorter time confirmed that the user had thought a particular thought.
77. Web Editor allowed browsing and editing files in folders on the web. I first planned the Web Editor algorithm. Then, I created new files and folders and displayed the name of the file or folder.  I could edit files.  I could add a feature to automate the development of my interpreter.
78. I could generate complex predicates, which considered past output, to search through. I wrote the program finder with types algorithm in the Philosophy folder.  Program finder was an algorithm that wrote algorithms from data, not to match it afterwards like Combination Algorithm Writer (CAW).  Program Finder with Types converted [a,b,c,d] to (((a:b):c):d) and recognised the parts of this compound to write recursive append, reverse or string_concat, etc. algorithms.  I also wrote an algorithm that used equals4 to recognise and substitute parts of compounds.
79. Jyotish guessed the person's thoughts from their financial details and tried to help them.  Separately, I wrote the Prolog Word Game.  In this, the game asked one player to guess the letters of the other player's word.  Then, the first player entered the word, which the algorithm hid. Then, the second player continued to guess letters, and the game told them whether they were correct or incorrect until guessing the word or running out of guesses.
80. Prolog's lists were more intuitive than not and were converted into C arrays.  I wrote the List Prolog to C converter.  I used the converter to convert List Prolog algorithms to C, speeding them up.  I used list Prolog to develop and debug the algorithms.  The program converted logical elements into if-then statements.
"]