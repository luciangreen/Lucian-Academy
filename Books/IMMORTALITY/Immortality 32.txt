["Green, L 2024, <i>Immortality 32</i>, Lucian Academy Press, Melbourne.","Green, L 2024",1,"Immortality 32

1. The immortal made a 3D array when the same structure repeated in a list and another array for terminals. I counted the number of items per level when compiling the list. I counted the maximum length of the lists. Or, I decided on an arbitrary value and wrapped the lists. In addition, I treated strings like lists of characters.
2. The immortal reused array structures whenever possible. I counted the number of levels when compiling the list. The number of levels contributed to the height of the array. I accounted for wrapping lists, which increased the height. The list items also contributed to the array height.
3. The immortal compressed strings where a short alphabet was used. I stored strings in one structure when compiling lists. The strings were split into character codes. They were compressed. Recurring substrings were stored once.
4. The immortal compiled a list in array form to parse it in C. I stored numbers in one structure when compiling lists. Numbers occupied a single cell, so the number array was narrow. I compressed numbers up to a limit. If numbers were over this value, they occupied two cells.
5. The immortal changed nondeterminism into C loops. There was nothing joined together or unpredictable. LLVM just deleted unused sequences of commands. I rewrote member, append, calls to predicates with multiple clauses, findall and similar predicates as loops in C. I included the whole program in one large function and renamed variables with the same name as those in the function.
6. The immortal alternatively used a counter. I converted findall over multiple predicates to findall in each predicate and then to loops in C. For example, the following predicate a1//1 finds the sum of pairs of values, and a2//1 finds these values and their sum the long way. The a2  predicate separates the collection and processing functions (which is more straightforward if collection involves multiple predicates) and is easier to convert to C.

% a1(D).
% D = [6, 7, 7, 8].

a1(D):-
findall(C,(c1([A,B]),C is A+B),D).

c1([C2,C3]) :-
 c3(C2),c3(C3).
c3(3).
c3(4).

% The long form of the above is:
% a2(D).
% D = [6, 7, 7, 8].

:-include('../listprologinterpreter/listprolog.pl').
a2(C):-c4(A),c7(A,C).

c4(C) :- A=[3,4],length(A,AL),
c5(A,1,AL,[],C).
c5(A,N,AL,B1,B2) :-
 (N is AL+1->B1=B2;
 (get_item_n(A,N,It),
 c6(It,A,1,AL,B1,B3),
 N1 is N+1,
 c5(A,N1,AL,B3,B2))).

c6(It,A,N,AL,C1,C2) :-
 (N is AL+1->C1=C2;
 (get_item_n(A,N,It2),
 append(C1,[[It,It2]],C3),
 N1 is N+1,
 c6(It,A,N1,AL,C3,C2))).

c7(A,C) :- length(A,AL),
c71(A,1,AL,[],C).
c71(A,N,AL,B1,B2) :-
 (N is AL+1->B1=B2;
 (get_item_n(A,N,[It1,It2]),
 It3 is It1+It2,
 append(B1,[It3],B3),
 N1 is N+1,
 c71(A,N1,AL,B3,B2))).

% or a2([6, 7, 7, 8]).
7. The immortal separated data collection and computation. NASA recommended functional decomposition. I simplified data collection to the data. Instead, I collected data from rules, files and input, possibly with prompts. Then, I type-checked this data and processed it as a value, string, or list of lists.
8. The immortal eliminated choice points in processing findall results by identifying whether all or the first result are required. I ran a child predicate to collect findall results. If processing was spread throughout levels of predicates, I split collection and processing at each level with a set of predicates. The algorithm collected data as simply as possible, without a findall command collecting and processing data from levels above. For example, the descendant predicate eliminated choice points by collecting data first and then processing this data.
9. The immortal merged predicates if their data took too long to decompose and build separately. To process findall results, I ran findall in the current predicate. I converted findall to a predicate, then to C code. It was better to separate data collection and processing because, for example, bulk translating Cultural Translation Tool sentences saves API quota. In addition, the grammar simplifier simplified the grammar in the interpreter (by grouping and simplifying) in preprocessing before processing it.
10. The immortal functionally decomposed and simplified (for C) predicate calls and header unification. Before this, I decided separate nested findalls were used to collect and process lists. Additional preprocessing was done separately, in multiple stages, as necessary. Dependencies of collection, preprocessing and processing were created, and stages were merged if results were needed before the end of operating on an item. If stage merging was necessary, it was clearly labelled as inseparable.
11. The immortal automatically type-checked predicates to help the user find bugs. I alerted the user about type errors such as split_string given a list. I type-checked predicates that took the same types, which were sometimes reserved. For instance, I checked that a list was [] or [_|_]. A list of lists was [] or a list of these lists.
12. The immortal used lazy evaluation to optimise algorithms. Values were only computed when needed. The results of infinite loops were often deleted. This redundant code could be deleted if necessary. Absolute references (i.e., only taking the first item) or relative references (such as taking data that fit a heuristic) were analysed to check the code’s necessity.
13. the immortal replaced references and computations with data if it led to a speed-up. I stated that any number raised to the power of 0 equalled one. For example, 1^0=1, 2^0=1 and 3^0=1. In addition, (-1)^0=1, (-2)^0=1 and (-3)^0=1. I simplified redundant code.
14. The immortal didn’t recapitulate finding solutions once they had found the first one. I identified “a(A) :- a(A).” or code with no changes to variables that called itself that led to infinite loops. In addition, I identified and deleted code that called itself after building a list. The interpreter stopped checking clauses when it found a result or checked all the clauses with findall. The interpreter needed a cut to stop going past the base case.
15. The immortal waited for the program to finish, in case it wasn’t in an infinite loop. I identified the infinite loop. I changed the loop condition inside each iteration. I never reset the loop continuation variable inside the loop. It was necessary to solve the halting problem in an applied way when writing the code.
16. The immortal removed the infinite loop if its output was unnecessary. Prolog returned multiple variables per predicate. Results only needed to be checked (and lists processed) when required. If a variable or list item was skipped, it didn’t need to be processed. Values were needed when printed or compared.

17. The immortal caught infinite loops. I removed infinite loops such as append(_,_,_). I listed possible infinite loops such as member(_,_). Unless string_concat(_,_,_) treated strings as lists, it produced an error. I modified them, inserting variables or removing them.
18. The immortal explained the algorithmic function to disabled students. I worked out the student’s family respected architecture. The data structure had an architectural seen-as version. The algorithm had structure and function. The function was welcoming.
19. The immortal celebrated nothingness, instead, an advanced algorithm. I gave a spiritual high distinction for so-called null computations. Text-to-Breasonings and mind-reading falsely appeared as null computations. By providing the high distinction using a spiritual system, I supported conclusions based on the software. The algorithm should compare items at the minimum, and the high distinction increases the comparison.
20. The immortal compressed algorithms using hash tables and mathematics. The maximum high distinction for a so-called null computation was 4*50 As. The high distinctions ranged from 80 breasonings to 4*50 As, where an A had 80 breasonings. The high distinctions were the output from Grammar-Logic, Breasoning Algorithm Generator (BAG) or Program Finder with Types (including Strings or PFTS). PFTS found unpredictable algorithms inside predictable ones, linking to variables and finding more relevant commands, possibly changing to multiple predicates or previous techniques with the Combination Algorithm Writer (CAW).
21. The immortal found internally and externally trending sentences and related them together. I checked that the entry was in the database. When finding combinations of two or more sentences when exhausting combinations in philosophy, I found only untaken combinations unless there was a development. Using the new philosophy, I found an algorithm related to the topic in the Text-to-Breasonings file. I chose a value and related the list with this length to itself in n^2 items.
22. The immortal replicated professorisms with simulated intelligence. I couldn’t change the code in the null computation algorithm. Instead, I simplified the code and retained the philosophical essence to remember. I found the simple nature of the algorithm. I applied it to the other major works, consolidating two-directional pathways between each pair of items.
23. The immortal aimed to program the simulation. I performed comparisons in the null computation. The most straightforward computation used maplist or another built-in Prolog predicate with a simple predicate. This simple predicate verified or built a list from data. The advanced algorithm was as efficient, inexpensive or quantum leap-like as nothing.
24. The immortal used neural compression to write an interpreter. I deleted true by itself. I rewrote catch, if-then//2 and //3 without true, wrote a command that ran Prolog in a container and made a programming construct that enabled parsing commands for higher-order programming. One could read the commands from a text file, convert them into List Prolog and run them with an interpreter. I experimented with converting from a programming language to C instead of using an interpreter for speed and rewrote C and assembly. I searched for a modern assembly interpreter.
25. The immortal inverted negative results into positive ones for shorter programs and easier verification (I compressed “nots” into shorter statements). I deleted clauses with false by itself. As with true, I rewrote commands that relied on false. I converted a predicate with a false base case to have a cut. I converted a predicate with false to long-form by using if-then. 
26. The immortal diverged the stage and verification bay. I used a neuronetwork to develop a CI/CD tool with many commands in a specific programming language. I worked out the set of indicated programs to convert the high-order algorithm and wrote them in C (it was like types). For example, I created an array with a certain length, such as the arity of a function. I predicted whether it would call a built-in, dynamic or other predicate from the code and converted the code in a custom language to C.
27. The immortal saved their life by teleporting between universes in the simulation. I found and deleted computations involving lists and strings that were always true or false. I tracked sets of systematic transformations and detransformations and deleted any unnecessary code. In addition, I used specifications to compute simpler code, possibly without other transformations (deleting unnecessary variables). I revamped algorithms to be more efficient by converting to assembly language, including neuronetworks.
28. The immortal converted higher-order functions to trivial functions by demarcating their function name, arguments and arity and converting them to long form. I converted trivial to complex predicates to always be true. For example, I found that whether hard-coded or data given by specifications always meant that C was A+B. I found whether predictable data always had the same result in a computation. I found two points when a computation was true.
29. The immortal simplified unification to the Herbrand Universe. I wrote that append([a],[b],[a,c]). was always false. I replaced always false statements with false. I predicted falsity in custom programming languages and higher-order functions and deleted them. I grouped and simplified patterns of falsity.
30. The immortal used Prolog to convert all programming languages. I integrated the C compiler code into Prolog. Many predicates were in C. It allowed assembly code to be written. I wrote a program that optimised each test case.
31. The immortal simulated assembly language’s interaction with the circuit. If I found true->a;b, I converted it to a, and if I found false->a;b, I converted it to b. If nested statements were revealed, I repeated this process as far as possible. The cross-language effectiveness was new, broached the frontiers and was approachable. I was confident in writing compilers, assembly interpreters and new technologies.
32. The immortal made everything into a game, such as making connections in philosophy. The exercise was to reduce the code’s complexity as much as possible before converting it to assembly by functionally decomposing it, uniformising it (reusing code), refactoring it given specifications, using simpler code and converting it to long form (in C). Connecting the simpler code to the other parts required our data, but education was more ethical. Thinking and thereness were the name of the game, while developedness (individuality) was the overall aim.

33. The immortal claimed that “a(2).” in “a(1). a(2).” might be dropped given a test, but the first instance of “b(1).” in “b(1), b(1).”) would be dropped because it is a duplicate. I stated that not((true, true)) was false. This statement was separate from “b” in Lucian CI/CD. For example, the tests would fail if “b” was false. If not((true, true)) could be returned to false from a previous version, it would be.
34. The immortal stated that (not(true)->true;not(true)) was false. This statement was because not(true) evaluated to false, failing the condition and selecting the second consequent, not(true), which is false. This construct, “a->b;c” is represented by the clauses “d:-a,b,!. d:-c.”. The first construct would be preferred in C. The second, preferred as an intermediate check by Prolog, can be checked by Lucian CI/CD, deleting either, both or neither clause (or their commands).
35. The immortal stated that any top-level false command in a clause falsified the clause. I stated that not((true, false)) was true. Separately, in “d:-a,b,!.”, “a” could only be omitted if it was included at the start of “b”. I wrote that not((true, false)) was the same as not(true) v not(false), by De Morgan’s Laws. In “d:-a,b,!. d:-c.” the first clause may be false, but the second may be true.
36. The immortal used simpler antecedents. I stated that (not(true)->true; not(false)) was true. I predicted the result of systems of if-then clauses. I removed if-then clauses with duplicate results. For example, “a->b;c” was equivalent to “not(a)->c;b”.
37. The immortal reduced cuts, preparing for C. I stated that not((false, false)) was true. Separately, in not((a,b)), if b=not(a), then it would be not((true,false)) or not((false,true)), both = true. The equivalent of not((false,false)) was not(false) v not(false), such as \"a:-true. a:-true.\". Prolog normally returned both of these, but in my implementation, the first correct one was returned unless findall returned both.
38. The immortal claimed that 1^(1v(0^1))=1. Separately, I stated that (not(false)->true; not(false)) was true. Separately, the following if-then statement has the following logic table:
a->b;c
a b  c
t co _
f _  co
In this, b and c may be considered but may be true or false. The statement may be represented as a clause or predicate of clauses, where always true or false relations may collapse in nested if-then.
39. The immortal rewrote In a->b;c as \"e:-a,b,!. e:-c.\" and a->b;d as \"e:-a,b,!. e:-d.\", where these could be merged to \"e:-a,b,!. e:-c. e:-d.\", meaning a->b;(c;d) or a->b;(c->true;d). (Separately, if I found a->false;b, I converted it to not(a)->b; false.) In a->b;c and a->b;d, I could write a->b;e, e:-c and e:-d. In a:-b;c and a:-d;c, I could write a->e;c, e:-b and e:-d. I could leave these clauses as they were in a:-b;c and d:-b;c.
40. The immortal took care to include the second consequent of the phi statement (A=[B]->true; A=B) in case the if-then statement failed. (Separately, I could further simplify not(a)->b; false to not(a),b.) In Prolog, a;b was written as a->true;b because b in (a;b) was sometimes skipped by the interpreter, but b in a->true;b was always run if a was false. I could temporarily replace a with true or false as a debugging switch. I could write a “phi” statement (A=[]->B=[a,[]]; B=[a, A]), which adjusted variables according to a condition mid-program.
41. The immortal wrote predicates in C that could perform custom tasks. I couldn’t write not(c,d) because this had more than one argument, so I wrote not((c,d)). This rule was similar to time//1, which timed a statement or findall//3 or forall//2. For example, maplist(atom, [a,b,c]) was true, maplist(append([a]),[[b],[c]],R) led to R = [[a, b], [a, c]], maplist(string_concat,[\"a\",\"b\"],[\"c\",\"d\"],R) yielded R = [\"ac\", \"bd\"], foldr(atom_concat,[a,b],'',R) gave R = ab and foldl(atom_concat,[a,b],'',R) resulted in R = ba. I used a custom predicate to keep count while I combined two lists.
42. The immortal stated that not((a;(b;c))) = \"d:-not(e). e:-a. e:-b. e:-c.\". I changed not((a,b)) to (not(a)->true; not(b)). This followed from not((a,b)) = not(a);not(b) = (not(a)->true; not(b)). Conversely, not((a;b)) = not(a),not(b). So, not((a;(b;c))) = not((a->true;(b->true;c))) = not(a),not(b),not(c).
43. The immortal changed the Prolog code “d:-not(e). e:-a. e:-b. e:-c.” to the C code not((a->true;(b->true;c))), in which processing and evaluating conditions are separated as ones goes. I changed (not(a)->true; (not(b)->true; not(c))) to not((a,b,c)). I preferred the latter form for simplicity. The former form allows replacing true with a command needed at those positions. Conversely, CI/CD may delete or modify any of “e:-a.” \"e:-b.\" or \"e:-c.\" in \"d:-not(e). e:-a. e:-b. e:-c.\" and convert these expressions back to not((a;(b;c))).
44. The immortal caught errors in State Saving Interpreter Web Service. It was necessary to simplify the code for correctness. I found findall that called multiple predicates. I caught errors in the code and displayed them. I simplified choice points by placing them in one place.
45. The immortal found the values passed to the web page and ran the predicate with these values offline to fix any errors. After a State Saving Interpreter Web Service error, I returned to a safe page. Instead of a 500 error, I displayed a page, the same whether public or private, saying there was an error. The programmer could use techniques to fix this error offline.
46. The immortal labelled C code with the Prolog code it used to be. I converted the list to numbers. I also used binary and other search trees in C. When storing multiple instances-of-a-value-stored-as-one-value hash tables, I diverged values that changed in one location and converged the same values. This technique was also true with hierarchical structures.
47. The immortal simplified the numbers 1,2,3 to a counter. The conversion from lists to numbers was a design decision. I labelled the C code with numbers with a Prolog key for the list. For example, I labelled one as “Harry”, two as 12, and so on. I traversed and copied these numbers, retrieving them from a structure and transforming them if necessary.
48. The immortal sped up the algorithm using faster methods. The conversion from lists to numbers gave better performance. Numbers took less space than strings or atoms. I converted from strings and atoms immediately and returned to them when needed.

49. The immortal stated that the list was more understandable than numbers. However, I put the relevant information in terms of numbers. I wrote numbers corresponding to characters in strings and atoms and list items. These list items started at a high number so as not to be confused with the other items. Numbers referred to themselves.
50. The immortal reverted to the interpreter on trace and control-C but used the faster code when compiled. There was a fast version of the code using long-form (without a large interpreter loop) and numbers instead of list items, and one resembling the user’s code, with lists intact. I explained the compiler producing this code. I compiled the code to single characters as predicate and variable names and compressed reused data. I only kept the long interpreter loop if backtracking couldn’t be done without it, and then converted as much of the code to long form and lists as numbers as possible.
51. The immortal verified that code changes were acceptable. I returned to a similar version of diff in Lucian CI/CD and GitL to the previous one, finding sequences of inserted or deleted items rather than one line at a time. I used the simple diff algorithm and, on a different item, found the sequence before the same item co-curred (sic). This improvement would decrease the number of insertions/deletions to find combinations. In addition, it would make identifying changes in diff files easier in Lucian CI/CD and GitL.
52. The immortal compressed different parts of the neuronetwork separately, like functional decomposition. The labels showed the items with a number representing them. I incremented the number of items to give the number corresponding to a new item. I compressed the data and labels table separately, like functional decomposition.
53. The immortal ran code for performance. I used compression to improve the code. It needs it anyway to get through it. The compressed code was shorter. For example, it used symbols instead of words and skipped over the interpreter.
54. The immortal didn’t require cuts at the end of grammars. I treated grammars like predicates. I converted the grammar to a predicate. It, including the code in “{}”, was in long form. The code in “{}” may include findall, converted to loops in long form.
55. The immortal simplified the grammar before converting it to a predicate. I treated grammars like predicates with list building. I merged grammars’ clauses into predicates when they were as simple as possible. I wrote grammars with disjunctions of parts. I split these into separate clauses for testing with Lucian CI/CD.
56. The immortal improved the grammar by eliminating unnecessary loops. I wrote grammars for parsing strings. The strings were lists of characters. I parsed these with a predicate. I merged the same characters and unmerged different characters, like a decision tree.
57. The immortal modified the term grammar to have different types of brackets or other delimiters than commas. Grammars were a good way of parsing strings. I converted the string to a term with term_to_atom//2. Conversion found whether the term would be properly formed. I processed the term normally.
58. The immortal graphed the data’s ontologies, showing types that fit into types. I converted the string to a list and got chunks of the list with append. Instead, I specified the possible characters in the chunk to eliminate errors. I warned programmers about ambiguous or missing parts of grammars and generated the correct grammar at the start. I generated grammars in the same way as algorithms with nested loops.
59. The immortal used a binary search tree for efficiency. I parsed the list with a predicate. I decomposed the list with A=[B|C]. Or, I used [D|E] in the predicate header. If the list was a list of lists, I used a hierarchical C data structure to represent it.
60. The immortal wrote philosophy to contact the future. I agree robots were uniform in coding. I used smaller sets of characters, commands, clauses, predicates and algorithms. I found human psychology was 2 in 2<-1, 2->3. It included us.
61. The immortal modified append or a simple algorithm. I used a de-blocker optimisation, unblocked bottlenecks, timed commands, and gave predicates the right time and complexity limits in Lucian CI/CD. 
62. The immortal helped the engineer find the bug. I checked types to prevent bottlenecks, fixed repeatedly reloading files, and made a type that limited the number of clauses. I could design anything I wanted, including a predicate that always worked, found ahead of time using mind reading and CAW.
63. The immortal found the ideal base predicate and connected the other predicates to it. I checked the code against neuronetworks. I found the code library using CAW. I first identified whether the base was append or another predicate. With this code, I created a decision tree, like a neuronetwork.
64. The immortal isolated and deleted unnecessary choice points. I checked that the predicate complexity was under the limit. I checked that the code was finished on time. I counted how many instructions there were per data item. I used the least number of instructions with the fewest computations.

65. The immortal generated algorithms and connective algorithms in CAW. The ideal code was available in the premium code checker. I wrote a version of CAW that wrote algorithms in Prolog. I tested them as part of CAW, not through Shell. I compiled the algorithm for speed.
66. The immortal recognised variable tables, including hierarchies of variables. I wrote a search algorithm using Program Finder with Types. I found it for terms, strings or lists. I found it for depth or breadth-first and pre-order in-order or post-order. I found sub-searches or an algorithm that followed a state machine.
67. The immortal checked the algorithm against the standards. The ideal code was ratified by law. I wrote the algorithm. I found a simpler algorithm with CAW with the algorithm’s specification. I checked the interpreter met the standards.
68. The immortal supported necessary commands in Lucian CI/CD. I identified and solved the algorithmic rant. I determined that tiredness or a mistaken presupposition had resulted in a falsely held belief that a particular feature would fix a bug. I found the correct configuration of changes using Lucian CI/CD. I wrote converters from the specific programming language to and from List [That Language] and a pretty printer and inserted the interpreter command.
69. The immortal eliminated complexities that went over data unnecessarily. I found and solved the algorithmic knot. Equals4 started as an algorithm that was knot-like and too complex. I simplified it using functional decomposition. It was as simple as considering what it did.
70. The immortal tested sequences of modules to test if they worked together. I found and fixed literary curses in programming. These algorithms that emitted the scent of  “archeology” were inexplicable or worked without one expecting them to. I simplified all the predicates in the algorithm. In addition, I corrected the algorithm by modularising its parts to test them.
71. The immortal philosophy student wrote the assignment in several parts. I allowed students to write longer code as long as it was simplified. The assignment was possible in the time. The philosophy students ran the algorithm. They tested it, found input for a particular output and understood how to write it.
72. The immortal educated students about Lucian CI/CD and GitL, customising them and using Program Finders to connect code (by finding places they could fit into or after each other to match types, then test these new algorithms, possibly deleting variables and predicates in the process). I committed the code in GitL when it had passed the tests. I checked that the tests passed, that they were the proper tests and that they covered the new features. The advantages of the version control system GitL were backdating to versions compatible with other software, checking progress in an assignment and keeping a record of changes by version. I backdated the version to fix a bug in a non-needed feature, in a mistaken feature or part of a feature.
73. The immortal tested that the single code line passed in Lucian CI/CD. I found combinations of lines from changed parts of code. I found that the line and its predicate met the test querying the predicate. I explained that the line may be incorrect even though it passed the test if the test was wrong, there were test(s) missing, or the test hadn’t been updated. If the line was verified to be needed, it was kept. Otherwise, I ran another test after changing or deleting the line.
74. The immortal kept sequences of commands leading to  “writeln” or a command with output only, which couldn’t be checked. Separately, the line was compared with nothing in Lucian CI/CD, so it was always checked. If a line was in both the old and new versions, it was not used to appear or not appear in a combination. The line was likely to be in the latest but not the old version, so it was used in the combinations. I treated commas (line delimiters) as insertions to remove in case one line was required.
75. The immortal stated that false and fail were equivalent. I checked that the line met the query test in Lucian CI/CD. I wrote the line and a containing predicate. I wrote the test, including the query and the result. If the test tested for falsity, I wrote it.
76. The immortal found the predicate set the error was in, where no code combination could satisfy the tests. I showed that Lucian CI/CD checked each predicate set one at a time. These sets were each predicate, or in the case of loops, sets of predicates that could only be tested together. In the case of predicates with multiple clauses, they were kept together and tested as late as possible so that predicates were tested bottom-up, as in the case of diamond-shaped dependencies (1<-2, 1<-3, 2<-4 and 3<-4). This shift in order was to prevent predicates, which included a clause that was usually tested last being tested first, causing disorder in the bottom-up order (i.e. 4,2,1,3, rather than 4,2,3,1).
77. The immortal avoided cybersecurity holes. I avoided “exploit” errors, which meant not finding code that exploited a vulnerability to carry out a malicious task. I avoided infiltrations and attacks.
78. The immortal claimed that completing computer science led to mathematics. I tested the recursive predicate in Lucian CI/CD. I included tests that tested the recursive predicate. Other predicates that the recursive predicate called but were not in the loop were tested separately. I could test parts of the loop by calling them as modules in another predicate and testing them separately.
79. The immortal suggested that custom dependencies were in the List Prolog Package Manager registry and could be entered in Lucian CI/CD verification tests. I considered supporting custom dependencies in Lucian CI/CD tests. I checked the types throughout the predicate with tests. I also allowed skipping tests (allowing any predicate that matched the predicate name and arity) or disjunctive tests. Finally, I allowed testing with findall to test for infinite results, which required a time limit.
80. The immortal proposed including file paths in tests to allow testing predicates that relied on other predicates for paths. I supported files at specified paths in Lucian CI/CD tests. These were files in the virtual file system, and errors in finding files were fatal and were fixed by saving and returning to an absolute path after setting a relative path. Lucian CI/CD tested predicates one at a time, so accessing files needed to be configured individually in predicates. If a predicate accessed a file, causing a problem because it was connected to another predicate, this predicate could be kept and skipped.
"]