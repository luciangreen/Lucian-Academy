["Green, L 2022, <i>Immortality 9</i>, Lucian Academy Press, Melbourne.","Green, L 2022",1,"Immortality 9

1.  I removed unnecessary levels of calls.  I found a:-b.  b:-c.  c.  I simplified this to a:-c.  c.  Before this, I simplified predicates to check whether they were the same by translating them.  They could be in another programming language.  Or they could be in another spoken language.
2.  I also removed unnecessary variables with the same surroundings.  I worked out and recorded removing the unnecessary variable from the state machine.  If the predicates were the same, I could delete the unnecessary variables.  They were names earlier in the predicate but were unused.  I only kept the only variables that I used.

3.  I assimilated and named the same algorithms, using nomenclature such as breasoning.  I did this by finding syno-functional algorithms.  These algorithms could multiply.  They could also paraphrase.  Or, they could induct.
4.  I discovered pedagogical thresholds.  Separately, I recorded the history of induction.  I did this by writing specifications for the scale of induction projects.  They got bigger.  I explained simulation algorithms from neural networks.
5.  I cognitively ordered the commands intuitively.  I grouped the algorithms by function.  I mind-mapped functions within other parts, etc.  I found how algorithms fit inside others complexly.  Finally, I fitted general language to specific arguments.
6.  I found better tools and conclusions with self, other and computational knowledge.  Before this, I ordered the predicates by output priority. Then, I questioned how vital the output was. Then, I asked whether algorithms would lead to different algorithms. Finally, I predicted the trajectory of the production with time.
7.  I aimed for large and small to be thought of clearly.   I used findall to keep one of a set of outputs in order.  In this, the first level of predicates produced a set of production.  The second level of predicates created one of these sets using findall.  I prepared for 100% correctness.
8.  I found the target and method of output. Third, I used dynamic argument ordering. Third, I reprogrammed the algorithm after splitting predicates into those with individual functions, which I could run one after another rather than complexly together. Fourth, I edited out superfluous arguments. Finally, I found the profession of writing.
9.  I used static XML argument ordering.  I did this by ordering the arguments alphabetically.  I also ordered the arguments at compilation time.  Reordering the arguments helped cognitively.  I noted the reused predicates. 
10.  I found a line of algorithms.  I repeated induction techniques using neural networks.  I split off other functions from predicates.  I over-split and then came back to needed combinations.  I kept the data and made simple models of more extended algorithms.
11.  I favoured simplicity and expansion.  I changed not(A), not(B) to not(AvB).  Also, I changed them back.  And I changed not(A) v not(B) to not(A^B).  I changed it back.

12.  I processed nested if-then clauses.  I worked out and recorded removing the tautology from the state machine.  For example, the tautology was true, or true->true.  I also simplified always failing parts to fail.  Finally, I simplified if-then clauses with true or false in the antecedent to the correct consequent.
13.  I inverted the modes of the predicate.  I ordered the predicates by usefulness. Then, I redrafted the predicate until it was simple. Fourth, I counted how many times I had used it.  Finally, I ordered the list of predicates by the number of uses.
14.  I recorded the history of bots.  I did this by preparing to create the bots.  I did this as part of my company.  Separately, I holidayed interstellar.  I holidayed intergalactically.
15.  I checked for an algorithm's relevance at the research frontier.  I started by ordering the predicates by importance.  First, I tested whether the predicate broke the border. Next, I cited whether I reused the predicate. Finally, I ranked the predicate by intelligence.
16.  I generated the test case from the type statement and wrote #+ to change the mode of arithmetic plus.  Separately, I found all test cases rather than running each one at a time.  I used findall to collect the test cases.  There were no total or test numbers to refer to necessarily.  I ran them, reusing libraries.
17.  I recorded Prolog command translations in Portuguese, Lithuanian, etc.  I did this to simplify spoken translation with algorithms.  First, I translated commands, n, v and Prolog symbols.  As part of this, I left data and names.  I referred to an element once.
18.  I only used simplify when necessary.  I modified equals4 to simplify by itself (fail when two or more items are in the tail).  I modified equals4.  I removed simplify from equals4.  If I located two or more items after \"|\" (in the tail), equals4 failed.
19.  I aimed to delete equals4(B, A).  I tested whether I needed the mirror of equals4(A, B).  I first wrote equals4 to try either (A, B) or (B, A).  The new version of equals4 deprecated this.  The old version treated the order differently.
20.  I supported nested lists.  I added support for \"|\" (pipe) to equals4_first_args.  I based it on equals4.  If there was a \"|\" in one or both lists, it affected how the interpreter processed the other list.  For example, [1,2,3]=[1,\"|\",[2,3]].
21.  I found unused predicates in e4_fa_get_vals.pl.  I converted the file to List Prolog.  I listed called predicates.  I wrote the names of any unused predicates in the file.  I deleted them.
22.  I added support for local and global stacks to State Saving Interpreter (SSI) by archiving and loading when a new predicate started.  At the start, I didn't archive the local stack to the global stack or load the local stack.  I did this when I started a new predicate at other times.  I also did it when I reloaded an old predicate.  I archived and loaded on changing the current predicate ID.
23.  I ran the multithreading command in C, with copies of the stacks and support for mutexes on global variables.  I added support for multithreading to SSI by using C's support for multithreading.  Multithreading duplicated stacks for each thread.  It supported creating mutexes for shared global resources (for example, asserted variables), not predicates. Next, I checked how many CPUs my smartphone had.
24.  I accepted input at the start and outputted the results at the end.  If one goal fails or throws an exception in multithreading, only it stops.  The others keep on going.  It is possible to return an error when a thread stops.  Or the interpreter may return a failure.  I researched I/O in multithreading.
25.  If multiple goals fail or raise an error in multithreading, errors or failures are reported per thread.  I accepted this was possible in C.  I used it in Prolog.  I caught failures and responded to threads finishing.  I scheduled retrying a thread.
26.  I prepared to write an algorithm database with algorithm IDs.  I transferred most of my work to my laptop (8 CPUs) from my VPS (1 CPU).  I used my VPS for web work.  I used the VPS for work during the day.  I also used my smartphone's many CPUs by running SSI in C.
27.  I quickly breasoned out thoughts, literally thinking of nothingness.  I simplified Text to Breasonings to more quickly breason out by object.  I did this by finding objects for all the words in the text.  I grouped the objects.  I breasoned their breasonings (dimensions) out all together. 
28.  I used multithreading in Text to Breasonings.  I breasoned out one object per CPU.  Grouping objects in this way sped up breasoning.  I presented visualisations afterwards of the result.  The result was a summary algorithm.
29.  I used mind reading in Grammar Logic (which mind-mapped essays) for necessary details.  I started by using multithreading in Grammar Logic. First, I found seven reasons per sentence, each on one CPU. Next, I found a sentence's reasons per CPU if there were many CPUs. After that, I wondered about mind reading.
31.  I used multithreading in Mind Reading Combination Algorithm Writer (MRCAW).  I did this by mind-reading mind-mapped parts at the same time.  I could also transfer mutexed globals between threads.  I considered a brain implant for better quality mind reading and writing of my algorithms. However, I ended up using neural networks.
30.  I examined each part of the music composer algorithm to consider multithreading, for example, searches for chord progressions.  I used multithreading in Mind Reading Music Composer.  I found lyrics when I had determined the main characters in previous parts.  I found the starting notes of sections and found the melody and harmony at the same time.  I filled in instruments for different sections at the same time.
32.  Detailed mind reading was better, and I tested multithreading for better results.  I used multithreading in Detailed Mind Reading in Essay Helper.  I worked on the exposition and critique simultaneously.  I worked on different paragraphs simultaneously, making sentences as used.  I worked on connections simultaneously, mind-reading topical sentences.

33.  There was an Unsatisfactory Progress Committee to help students when they performed poorly.  I did this to support agreement and disagreement in the academy.  The student first agreed or disagreed with the essay topic.  They disagreed with causality.  They received a lower grade.
34.  The fail was borderline if there were a few unsure disagreements in the first half.  I supported success and failure in the academy.  I explained the marking system to the student.  They read the text and decided whether to agree in the first half.  If they disagreed in the first half, they failed.
35.  Business included conscious thoughts and solved problems.  It did this when supporting positive and negative terms in reasons.  As part of this, I identified possible negative or unusual positive thoughts.  Then, I protected people from them.  The thoughts prompted people's curiosity and thought.
36.  I changed the test cases to Prolog. Next, I changed v to vsys in List Prolog to use the string \"v\" in data.  I did this by writing vsys in the settings file. Next, I read vsys each time I ran List Prolog. Finally, I converted Prolog into List Prolog with vsys identifying variables.
37.  I used \"n\" in games in Prolog.  I changed n to nsys in List Prolog to use the string \"n\" in data.  I wrote nsys to identify the names of predicates.  The word \"nsys\" didn't appear in Prolog.  The Prolog to List Prolog converter inserted it.
38.  I changed the converter to support definite clause grammars.  I changed -> to --> in Prolog.  The longer array denoted definite clause grammars.  Their name meant they always had a predicate body.  I reserved -> for if-then clauses.
39.  When installing a language, I translated all the needed words at once to save the API quota.  I simplified language translation in List Prolog.  I detected whether there was a dictionary entry for the term.  If translating to long-form English, I changed underscores to spaces.  I only translated reserved words.
40.  I ran one frame at a time in multithreading.  I called each \"thread\" part of the Prolog thread.  I ran one frame (like a trace line) per thread, where the C code was in a separate function.  I accounted for mutexes around predicates and globals, running predicates or accessing globals only if the user unlocked their mutex.  I simplified SSI to have two SSI predicates.
41.  I controlled mutexes manually.  The algorithm contained a mutex wrapper.  With this wrapper, the algorithm couldn't run the same part of code with the mutex simultaneously in different threads.  The SSI state machine recorded the mutex number next to the code inside the mutex.  Mutexes behaved like the \"once\" command.  

42.  I remained active and entrepreneurial through investments.  I simulated sales in the academy.  First, I bought the product for people.  I mind-read their assignments.  Later, I sold to real people on the side separately.
43.  I used program finder with CAW to mind-read computing assignments after encouraging students.  I did this to mark the academy assignment.  Also, the institution updated the high distinctions over many years.  I detected the number of breasonings over a period.  The students completed the tasks over several periods.
44.  I changed \"I wrote the key terms to simplify the sentence\" to \"The students found or inferred the key terms, for example, the computational verb and data (input and output)\".  I simplified the sentence.  I reduced the sentence to its critical terms in base form.  I sometimes separated different sets of keywords.  I checked whether these could converge and simplify.
45.  I used the \"text to algorithm\" algorithm to write a predicate about the keywords in the sentence.  The predicate was representative and complex enough to convey the idea.  I converted to either predicate head and recursive call containing list processing head and tail or list processing using A=[B|C], etc. in the body.  I noticed that algorithms with the same computational verb had common elements, so I sped up finding predicates with the data (or vice-versa).  If the data didn't lead to a predicate, the user needed to enter one.
46.  I wrote a sentence in terms of language from the other sentence.  I read the original sentence.  Then, I entered the new sentence given the other sentence.  I used the output if it was grammatical and logical (it was in the database and not too creative or mad).  I replaced the words with the closest (synonymous/functionymous and intersectional), which made sense.
47.  I engaged the student about the political dimensions of the philosophy.  Before this, I detected the student thinking about an argument. Then, I thought about the connections. Third, I thought about the algorithm. Finally, I completed paragraph 46, for example, on the topic of breasonings as algorithms, connected to the first technique. The new sentence was \"I asked what intelligence the geometry posed\" (where the first technique was hermeneutic or question answering).
48.  The structure of the school was to allow students to write when they wanted to, finding out and writing books.  I increased the student's argument.  In paragraph 47, the political side of breasonings might encourage studying doctoral degrees and writing 4*50 As (400 page) long books on a department. Looking for a doctoral degree would encourage originality and responsibility in academia, schools and industry.  I streamlined the assignment and urged students to talk to me with their questions.
49.  I solved negativity to myself.  I always wrote in terms of favourable terms.  There was positive problem-solving and algorithm writing.  I analysed positive society based on algorithmic currency.  The person received a pension and wrote without worrying about money.
50.  Over time, I appreciated criticality to help the academy remain rigorous.  In the vocational education version, a careful algorithm wrote critical content automatically.  In religion, there was important content on top to maintain order.  Everyone passed or failed in vocational education, and students rewrote answers to \"what\" questions. So I researched essay writing and algorithm writing in vocational education.
51.  The difference between school and University was that lecturers mind-read University students' thoughts.  I noticed that mind reading improved the rigour of students' ideas.  I trained students in medicine, education and meditation so that they enjoyed mind reading.  It might be unnecessary for non-spiritual meditation students to take part in computational mind reading, but they could hand-breason out breasonings.  The texts were written inclusively, with critical analysis everyone could complete.
52.  There was a hybrid vocational education/University system.  In this system, there were more As, and they were well-ordered.  In this system, the assessment was easy, and students were mind-read (interacted with artificial intelligence).  Vocational education was single-grade-minded, so students were mind read on straightforward questions, and the computer funnelled everything into categories of knowledge.  When studying vocational education, I siphoned my interests in mind reading and text to breasonings.
53.  Secondary schools had favourable terms around a negative word.  Meditation school staff sometimes protected from this type of thing by becoming the person's ally and objectively or understandingly discussing the issue.  The \"negative term\" was a juvenile misunderstanding or rebelliousness.  Meditation could help relax and increase cognition about and possibly prevent these events.  I agreed with a good diet, sleep, avoiding drugs and alcohol and good support with study and development during this time.
54.  A doctorate helped support me in primary and secondary education and meeting business standards.  I hand-wrote and interpreted 80 algorithms for sales and assignments.  Hand-writing algorithms was rather than putting off writing specifically, where one shouldn't generate breasonings too quickly.  Also, this was in addition to writing 80 philosophy breasonings, where writing algorithms helped examine the student's thoughts properly and satisfactorily.  I found pursuing a business doctorate was intersectional (appropriate) for me and helped support me in writing enough such algorithms.
55.  I noticed that some academics detailed their 400-page books, taking many years.  I wrote longer algorithm sequences for some assignments and sales.  Some projects required 4*50 As, which is possible to support with a doctorate.  Some sales also required 4*50 As to be completed from both parties' point of view and a doctorate.  I experimented with writing for over a year instead of six months to include the algorithms with the 4*50 As.
56.  I didn't just back-propagate a value from side to side of equals4.  I added back-propagation of values B=1 to A=B before it.  For example,
equals4(A,B),equals4(B,C),equals4(C,1). A=1, B=1, C=1.  Also, I entered equals4([A,B],C),equals4(C,[1,1]), returning A=1, B=1, C=[1,1].  Also, I entered  equals4([A,A,B],[C,D,D]),equals4([E,E,B],[1,G,G]), returning A=1, B=1, C=1, D=1, E=1, G=1.  
59.  I changed equals4 to \"=\".  I converted this \"=\" symbol from Prolog to List Prolog.  I removed equals4 as a command.  I also removed equals 2 and 3.  Separately, I reused code in the Philosophy algorithms lpi and lucianpl.

60. I found our common interests. I found intersection(A,B,C) with no values.  I entered intersection([E,B,C],[B,C,D],A).  The interpreter returned E = B, B = C, A = [C, C, C].  Entering no values allowed faster computation.
61.  In the intersection command, the result had the same number of items as the shorter input. Separately, I found union(A, B, C) without values. I entered union([A,B],[C,D],E).  The interpreter returned A = B, B = C, E = [C, D].  The interpreter merged undefined variables.
62. I found maximum(A, B) without values. I entered maximum([A,B,C],D).  The interpreter returned E, where E>=F, F>=G. The maximum result without values could be in the bindings table. It was like co-routining (where dif(A, B) can be in the bindings table and returns true if not(A=B)).
63. I found the maplist(predicate, List, Result) command without values. I entered foldr(p,[A,B,C],D).  The interpreter returned D=p(p(A,B),C).  I could store this result in the variable bindings table. Also foldr(p,[A,B,C],D,E) returned E=p(p(p(A,B),C),D).
64. I computed the free proof. I found add(A,B,C) without values.  I entered sum(A,B,C).  The interpreter returned C is A+B. I stored this in the C variable, and the interpreter evaluated it when A and B were defined.
65. I found findall([A1,A2...],(member_and_rules(...A1),member_and_rules(...A2)),B) without data.  I entered findall([A1,A2...],(member_and_rules([C1...CN],...A1),member_and_rules([D1...DM],...A2)),B).  The interpreter returned N*M... lists where N and M were the list input lengths, respectively. I stored a mathematical expression of the result for B. I found failures, such as odd numbers, mathematically.
66. I wrote the database formula finder. I found subtract_set(A,B,C) without values.  I entered subtract_set([A1,A2,A3],B,C).  The interpreter returned A1 = A2, A2 = A3, B = [A3|_], C = [].  I stored what I wanted (the predicate name in the variables).  
67. I found delete(A, B, C) without data. I entered delete([A,B],B,C).  The interpreter returned C = [A].  If I wanted an explicit result, I could enter delete([1,2],2,D), returning D = [1].  I also entered append([A],[B],C),delete(C,A,D), returning D = [B].
68. I increased the assignment to be like research. There was always a new idea in this project. In the project, I kept track of the possibilities and perspectives. There could also be multiple perspectives. I helped the student to them.
69. I generalised the free expression (I removed the brackets). Before this, I increased research to be like an assignment. I did this by working on the probable questions. Further, I compared the research with existing research. Finally, I changed the standard to achieve future possibilities.
70. I corrected the reasoning in a private consultation. I did this by recalling the conversation thread. First, I added the ideas. The student then wrote them down. Next, I generated business (mathematical bindings) research. Finally, I wrote that the free binding equalled 1+1=2.
71. I examined the literature about a topic. Then, I was free to make decisions about it. I could design it freely. I could also verify freely. In this way, I learned about one type of work.
72. I examined simple and extended ideas. Separately, I recommended time travel to the meditator. First, I travelled from home to the centre. Then, I practised meditation. Finally, I neurospected (sic) writing to time travel.

73.  I categorised the tasks and worked on them.  I watched the Brunei sword dance.  I prepared the art.  I composed the music.  I synthesised the highlights of the philosophy.
74.  I worked on the correct form of the cut command.  I compared the behaviour of various positions of cut in Vetusia with Prolog.  I found the different behaviour of the cut command at a particular place.  I found the reason for the behaviour.  I changed the algorithm to behave as I wanted.
75.  I time travelled to the time of the important academic.  I thought of this by creating a box puppet theatre set in the times. First, I made puppets of me and the intellectual. Then, I created a script in which I asked the academic what his favourite implementation of Prolog was.  He answered, \"List Prolog\" because it was essential to start at the beginning.
76.  I verified the definitions of cut and inserting cut when possible in optimisation.  As part of tail recursion optimisation, I added a cut command in List Prolog, not state machine form.  I experimented with adding the cut command in state machine form.  The advantage was locating the final command more easily.  In the case of member(A,[1,2,3]), !, I changed it to A=1.
77.  In tail recursion optimisation, I found the last commands.  I did this by examining the algorithm in state machine form.  I started by finding the last commands in each predicate. Then, I inserted brackets around each of them. Finally, I inserted a cut command before them.
78.  I didn't have to search through the algorithm; I found choice points in runtime with the interpreter to determine whether to insert the cut command.  In tail recursion optimisation, I inserted the cut command if there were no commands with choice points in the predicate (usually when it was the final clause) or if there was a cut so far.  I verified that there were no choice points with the current predicate number touching through a link.  If it was the final clause of a predicate, then there were no more recursive calls before the last command.  If there was a cut so far in the predicate, tail recursion optimisation already worked through the cut command.
79.  I verified whether tail recursion optimisation sped up Vetusia. Otherwise, I tried adding a local stack or reusing globals. Then, I activated tail recursion optimisation with a possible cut for the rest of the predicate. First, I checked that there were no choice points just before the findall recursive call of the predicate (including other clauses).  If there were no choice points, then I inserted cut before the last recursive calls.  Cut removed unnecessary stack data, approaching the efficiency of a C for-loop.
80.  I counted the calls to each predicate in each predicate.  Before adding a tail recursion optimisation cut, I checked for a recursive call or call of call.  The definition of a recursive call was a previously called predicate.  I could also check whether the call was to a predicate, and so on, that called a previously called predicate.  I could check for these calls in the state machine.
"]