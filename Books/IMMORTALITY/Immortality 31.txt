["Green, L 2024, <i>Immortality 31</i>, Lucian Academy Press, Melbourne.","Green, L 2024",1,"Immortality 31

1. The immortal ran the Prolog algorithm like a program in C, saving memory. Assuming choice points are contained, rather than a Prolog optimiser treating dynamic predicates as added arguments, it can treat them as globals. If a sequence of predicates fails, the globals will be intact. The command retractall(predicate(_)) (assuming a:-dynamic(predicate/1) declaration) would initialise the stack for a particular dynamic predicate as a global. The command assertz(predicate(x)) would add x to the predicate as a global.
2. The immortal optimised the algorithm to find the item at an address with arrays. I used subterm with address to quickly traverse terms. If a Prolog predicate always jumped to an absolute address (or address relative to an address), I jumped to it with a subterm with an address. I analysed the code to find the address. I got the item at the address, transformed it and substituted it.
3. The immortal updated the algorithms for different processors. I skipped constants if they were already there. I didn’t verify previously verified constants. I converted Prolog to C to run it faster. I familiarised myself with assembly code and optimised code for various machines.
4. The immortal edited the Lucian CI/CD document in “diff” view. I found efficient algorithms in Prolog and assembly language with Combination Algorithm Writer (CAW). I simplified the data. I focused on the first necessary outputs. I counted the length of the string in assembly language.
5. The immortal used C structs instead of arrays for complex data. I used C structs to represent lists of lists. I identified different repeating structures. I counted the number of items per level and number of levels. I stored strings and numbers in one structure.
6. The immortal changed nondeterminism into C loops. I converted findall over multiple predicates to findall in each predicate and then to loops in C. I separated data collection and computation. I ran a child predicate to collect findall results, then ran findall in the current predicate. Separate nested findalls were used to collect and process lists.
7. The immortal alerted the user about type errors such as split_string given a list. I used lazy evaluation to optimise algorithms. I stated that any number raised to the power of 0 equalled one. I identified \"a(A) :- a(A).\" infinite loops and removed them if their output was not needed. I removed infinite loops such as append(_,_,_).
8. The immortal worked out the family respected architecture. I gave a spiritual high distinction for null computations. The maximum was 4*50 As. I checked that the entry was in the database. I couldn’t change the code, although I performed comparisons.
9. The immortal deleted true by itself and clauses with false by itself. I found and deleted computations involving lists and strings that were always true or false. For instance, string_concat(“a”, “b”, “ab”). was always true. Also, append([a],[b],[a,c]). was always false. If I found true->a;b, I converted it to a, and if I found false->a;b, I converted it to b.
10. The immortal stated that not((true,true)) and (not(true)->true;not(true)) were both false, not((true,false)) and (not(true)->true;not(false)) were both true and that not((false,false)) and (not(false)->true;not(false)) were both true. If I found a->false;b, I converted it to not(a)->b; false. I could further simplify this to not(a),b. I couldn’t write not(c,d) because this had more than one argument, so I wrote not((c,d)). Also, I changed not((a,b)) to (not(a)->true; not(b)) and the reverse if there were more than two arguments.
11. The immortal caught errors in State Saving Interpreter Web Service and returned to a safe page. I converted the list to numbers. This conversion was a design decision and gave better performance but was less understandable. The code had one version with strings and one with numbers, with labels showing the variable with a particular type. In the end, I ran code for performance.
12. The immortal treated grammars like predicates, for example, with list building, for simplicity. I wrote grammars for parsing strings. These were a good way of parsing strings. Alternatively, I converted the string to a list and got chunks of the list with append. I parsed the list with a predicate if I needed a more straightforward solution.
13. The immortal agreed robots were uniform in coding. I used a de-blocker optimisation that checked types, checked code against neuronetworks and that the predicate complexity was under the limit. The ideal code was available in premium code checkers and was ratified by law. Rants, knots and literary curses were against the rules. Students may write longer code as long as it is simplified.
14. The immortal could commit the code in GitL when it had passed tests. In Lucian CI/CD, I tested that the single code line passed. The line was compared with nothing, so it was always checked. I checked that the line met the query test. Lucian CI/CD checked each predicate set one at a time.
15. The immortal avoided “exploit” errors. I tested the recursive predicate in Lucian CI/CD. I considered supporting custom dependencies, files at specified paths, file date data and program error codes in tests. Both clauses of the predicate were kept when it passed the tests. Lines would only be added from the previous version or removed if needed to construct the shortest version that satisfied the test.
16. The immortal tested multiple repositories, some with no main predicates (but which were used by other repositories). I tested different contents of main_file.txt (in each repository) in Lucian CI/CD. I tested combinations of one, two or three predicates per file and one, two or three files. These were the main predicates that called the other predicates in each repository and the files they were in. Later, the algorithm could detect these predicates.

17. The immortal used Lucian CI to test and CD to build algorithms from combinations of past versions. I tested Lucian CI/CD with one, two or three predicates per file. I assumed it would work with more predicates. I tested the limitation of the predicates available with Prolog to List Prolog. For example, I wrote “:-include”, “findall”, and a custom predicate name.
18. The immortal debugged Lucian CI/CD on 15.1.24, integrating test 9 (which found combinations of lines) with tests 1-8 (which tested code), then fixed problems with test 5 (which needed simpler testing), then test 9 again, then test 5. I tested one, two or three files. I included and gave tests for different predicates. I used different files for features, shared predicates or main and subpredicates. I corrected problems by keeping the algorithm simple.
19. The immortal preferred maplist to predicates, but both were good (they could convert maplist to a predicate). I tested three files with three predicates in Lucian CI/CD. I finished Lucian CI/CD to test different algorithms, find combinations of previous code to avoid mistakes and give it as input. These files could include others, but by saying multiple files, I meant new main predicates within each one. These main predicates weren’t necessarily connected with other predicates.
20. The immortal claimed that Combination Algorithm Writer (CAW) is more complex than Lucian CI/CD and could reorder arguments and commands. Lucian CI/CD could find 1+1=2 from 1+0=1 and 0+1=1. It could find string_concat(“a”, “b”, “ab”) from string_concat(“a”, “”, “a”) and string_concat(“”, “b”, “b”). In addition, it could find append([1],[2],[1,2]) from append([1],[],[1]) and append([],[2],[2]). If a main_file.txt refers to no files (with predicates), it must contain [].
21. The immortal planned to bug-test multiple Lucian CI/CD clauses. I used the Package Manager’s registry file of dependencies of repositories in Lucian CI/CD. I entered more and removed some variables from Lucian CI/CD’s unit tester. I made Lucian CI/CD as simple as possible and allowed changing the maximum number of items to find and test combinations. I merged CI (testing) and CD (combination finding), although they were easier to test separately.
22. The immortal temporarily represented dependencies as relation lists. I reused dependencies in Lucian CI/CD tests, which I noted in the readme file. I created original Lucian CI/CD test dependencies, including terminals and circular references, which the List Prolog Package Manager (LPPM) resolved. I planned to resolve circular and duplicated “:-include” references in Prolog. I temporarily used new dependencies in Lucian CI/CD.
23. The immortal tested the predicates bottom-up, no matter what order they were in the files, and used “:-include” statements as needed. I tested multiple files in Lucian CI/CD. I merged the files with delimiters, separated comments (using only those in the new version) and code and tested combinations within predicate dependencies. I used the same algorithm for checking and changing code and more easily fetched and used tests. To simplify the display, I eliminated duplicate loaded files in Lucian CI/CD.
24. The immortal checked that dependencies and “:-include” statements matched. I tested the non-mentioned files in Lucian CI/CD. These files were connected with “:-include” statements but were not mentioned as main files with main predicates to test. I tested the files’ predicates from the main repository. I fixed an error in the tests, so the other repository’s predicates were tested from them, and the main_file.txt referred to them. Repositories were constantly tested separately, not relying on “:-include” statements.
25. The immortal tested, changed, and bulk uploaded multiple repositories. I tested various repositories in Lucian CI/CD. I made repositorilets (sic) for files that two repositories needed when one repository depended on the other, and it was better not to store them in the upper repository. I shuffled files in and out of these repositorilets, used by the same repositories. A third repository could access them if they were small enough, and they were turned into a hierarchy of repositories if necessary.
26. The immortal notified the user about and helped correct circular references. I tested circular references (repositories that were loaded twice). LPPM detected and removed circular references on loading. Lucian CI/CD detected and aborted on circular references using “:-include”. I created neuronetwork material using CAW.
27. The immortal tested loops within loops in Lucian CI/CD. I tested loops in Lucian CI/CD. Loops included all the predicates in between. Looped predicates were tested together, but dynamic predicate arcs were also tested. This reduced options to find combinations within the predicates but was necessary because a recursive predicate worked as a unit, and globals couldn’t easily be given as input in the middle of a dynamic arc. Hence, they needed to be tested together.
28. The immortal tested multiple predicates in dependency levels. I tested loops across files and repositories in Lucian CI/CD. The code was continuous, as it was in the same code group. I could test it with a single query. I tested lower code than the loop in the other repository with other main_file.txt entries.
29. The immortal claimed that a particular modified clause would retain its position in the future. I tested multiple-clause predicates across multiple files and repositories in Lucian CI/CD. The order of predicates was retained from the original. They were in the correct files and repositories. Their location was moved to the first repository and file the predicate was in.
30. The immortal reassured the person that Lucian CI/CD functioned, given any input configuration. I tested the predicates in reverse order of the predicates in main_file.txt and bottom-up order. I tested each of these three orders when they were out of order compared with each other for correctness. Different files complicate this order. In addition, it is complicated by multiple repositories, “:-include” dependencies and other dependencies.
31. The immortal stored deleted code in a safe place. I wrote a single command to move Lucian CI/CD output to the GitL folder. This command copied the output to the GitL test folder and committed it. I could see the changes to the repository concerning time. I could publish selected commits to the public when they were stable. 
32. The immortal custom-built Lucian CI/CD to help simplify code, ready for optimisation. When testing, I saved and restored Github_lc/* Lucian CI/CD status files. These files recorded the status of testing from current repositories. They were temporarily moved away during testing, which created new configuration files. I could optionally store and inspect these temporary files for debugging.

33. The immortal developed in Lucian CI/CD and presented in GitL. I displayed the “diff” between the start and end in Lucian CI/CD in Prolog. I saved this diff to the log. I saved the files if necessary. GitL saved the diff between the two commits.
34. The immortal entered numerous equivalent logical structures. I included options to recognise specific languages’ syntax in Lucian CI/CD. I converted between the language and list format and back. I entered examples of the language to create the converters. The creator algorithm saved different ways of representing the same logical structures.
35. The immortal stated that A=a,B=[[v,c],d],E=[[n,A],B] gave the result E=[[n,a],[[v,c],d]]. I recognised the other language’s variable format. I found the variable name. I found its syntax, including symbols and case. I devised a new predicate name as a variable name in Prolog to replace “univ”.
36. The immortal observed the structure of commands containing several lines. I recognised the other language’s lines. I found the command names, variables and their associated syntax together. I found the line separator or delimiter. I observed the syntax of the final line in a function.
37. The immortal wrote a language with minimal syntax. I recognised the other language’s functions. I found the line’s contents. Between them, I found the function header’s contents. Differentiating between code and comments, I delineated the function format.
38. The immortal gave an error on an undefined variable name as a predicate name. The compiler compiler wrote the logical back end using program finders. I did if-then//2 and //3 and not//1 using predicate calls. I parsed the algorithm file using the list of predicate forms. It was not too tricky to use variable names as predicate names.
39. The immortal claimed that quantum mind reader gave 14-16% more accurate results than random. The compiler compiler wrote the command back end using program finders. Program finders recognised the need for a particular program and customised it for a purpose. For example, the command string_concat took two strings and concatenated them together. A not-necessarily quantum algorithm ran nondeterministic predicates at the same time.
40. The immortal generated simpler algorithms with a quantum mind reader as a substitute. The compiler compiler wrote the back end using examples of trace. I recorded the results of commands, algorithm steps, and evidence of backtracking. I wrote the rules of the backtracker. I used a quantum mind reader in cases when I didn’t know the answer.
41. The immortal explained that “big idea” algorithms housed small idea algorithms and that new ideas were sometimes intelligent. I converted descendant in family.pl from Prolog to (List) Prolog. In the first sense, I directly converted the long form of descendant from Prolog to List Prolog. In the second sense, I converted the short form of the descendant algorithm to its extended form, or vice-versa. This conversion was an example of a “big idea” algorithm that was possible on the non-interpreter side.
42. The immortal passed the list to find a member of the second time to the second clause in the predicate converted from findall. I changed findall to a predicate. In this, choice points were separated into data collection and processing by loop level and unique choice points were converted to clauses. I read and manipulated the findall code, and the algorithm created the long-form code. The only problems were dynamic predicates (solved using globals) and multithreading given backtracking (solved using a different intermediate predicate).
43. The immortal converted a cut represented in long form Prolog to short form Prolog. I converted Prolog to C. I noted that cut took the first result of the predicate and separated rules before the last cut into different predicates so that they could each be pruned. A cut was converted into a predicate by stopping after finding a result rather than returning all results. Complications such as finding n solutions and simplifying code that explicitly found n solutions were also possible.
44. The immortal processed the output of subterm with address within subterm with address. Earlier, I processed the list of lists with subterm with address. I stored certain types of items at a level. I stored further types of items at particular positions. I integrated the processing code with the subterm with the address algorithm, only using the label matching and list output parts.
45. The immortal processed data using Prolog terms for simplicity. I converted the result of subterm with address to a string. I converted the hierarchy nodes to strings and traversed and concatenated them. I converted the string to a hierarchy with a grammar used to find the algorithm that converted the term to a string. The term form contained [“()”,[“a”]] for example, and the string it represented was “(a)”.
46. The immortal processed similar data using the same predicate but different flags. Before this, I used labels to process lists of lists with subterms and addresses. I found the labels using subterm with address. I processed the requisite data accordingly. It was if data with another label needed to be processed differently for each result.
47. The immortal stored scavenger hunt items throughout the computer game about the universe through time. I stated that finding and operating on multidimensional terms would be more difficult without labels. I found items with the label ‘a’ in:
[
[a,b],
[
 [a,c]
]
], returning b and c at specific addresses. The labels could contain metadata such as variable ID and algorithm ID and could link to previous data. The variable ID referred to the origin of the data, with an example or description and the algorithm ID referred to the algorithm that a flag helped express.
48. After the following, I found the possible types for each line and put them together bottom-up. I stated that with labels, building lists, for example, converting data to types, was more straightforward. I converted the data to long-form types without variables. I inspected different data sets and inserted variables for recurring types. I found and converted the labels for types into short-form types with subterm with address.

49. The immortal stated that multithreading is easier with C code. I stated that finding types replaced testing. Instead of writing tests, I found whether the algorithm types agreed by inspecting the code. I found types for dynamic predicates top-down. To optimise dynamic predicates, I predicted higher-order functions from the code and converted them to C.
50. The immortal only used globals sparingly because they were harder to test. I stated that dynamic predicates had a structure determined earlier. Dynamic predicates were declared at the start or in code (found in compilation) and asserted in code. As part of optimisation, possible structures asserted meant that dynamic predicates were asserted with lists from other variables. While other choice points, including nondeterministic clauses, were loops, dynamic predicates were left as globals (where they were discouraged and converted to local variables where possible, and inter-predicate globals were converted to passed variables to remove possible bugs).
51. The immortal stated that types were found top-down from dynamic predicate definition to use. The local variables, converted from globals and converted from dynamic predicates, were labelled in the comments. The point of execution passed these local variables around long-form code so that they were available in current form at any moment. These converted variables were more accessible than variables trapped in findall, which needed wrapping in a function and failure cases needing phi nodes (if-then cases) to choose whether to return variables (such as free variables in bagof).
52. The immortal claimed everything was predictable with enough specs and regression. I found predictable patterns in types. It was more efficient to use inductive code specialised to find predictable patterns. I identified and simplified non-simple code that found predictable patterns to match patterns. I labelled predictable code so as not to become distracted by it when optimising non-predictable code.
53. The immortal thought of a golden trophy, and it existed. Beyond Prolog required regression. After finding the code, I didn’t reaccess the code. It was not necessary to think in code. My friend James could think of anything in mathematics, and it was fun.
54. The immortal claimed sub-term with the address presented information at one’s fingertips. I identified unpredictable types. These were not predictable changes in patterns, such as D1=[A, B, C], D2=[C, B, A]. One needed to ensure that seemingly predictable patterns were not unpredictable, requiring additional conditions. I distinguished between errors unpredictably leading to correct results and unusual, correct optimisations (where another improvement might be), thinking like sub-term with address and converting to a long-form predicate to run more quickly.
55. The immortal checked whether the unpredictable code was in the database; otherwise, it was added. I wrote that unpredictable types relied on non-pattern-matching code. For example, non-pattern-matching code was more challenging to find, such as searching, sorting or other transformations. In some cases, unpredictable code could be refactored using techniques to remove unnecessary features. I researched whether binary programs were faster than C.
56. The immortal combined the grammars. I found combinations of unpredictable code (such as decision trees, search or sort algorithms) with program finders. I wrote grammar checkers, translators, grammars, programming language converters, or combinations. I checked against the grammar, converted between grammars using parts of speech, used a grammar and term parser, checked a translation, checked a programming language or translated the programming language. The term parser could parse lists with different delimiters.
57. The immortal modified shorter versions of code. If needed types were missing, I wrote new code. I wrote the input and output types. If their patterns didn’t map, I treated all input variables as inputs into the regression and the outputs as outputs. Alternately, I tried single commands from the database diff combinations if merging two interpretations or versions or shorter versions of code.
58. The immortal created two variables from a variable to process them separately. I wrote a new command to connect gaps in unpredictable code. I skipped over the easy ones and wrote the hard ones. It took concentration to work out answers. There was a more intelligent connection, a new variable.
59. The immortal represented terms as tables in C. I used subterm with address instead of another predicate. Instead of a predicate that recursively searched levels of a term and processed its results in different clauses, a subterm with address found occurrences of a subterm throughout the term. Subterm with address was a short-form algorithm, while the other predicate was the long-form algorithm, where subterm with address represented how one thought by “collecting” results using a single method and the long-form predicate joined search to processing, risking missing brackets. Processing routines from subterm with the address were substituted into the predicate for faster running in C.
60. The immortal let subterm with address search for terms and give addresses so they could substitute the transformed terms back. I found subterms to process with findall. For example, I labelled term parts to find later,
?- sub_term_wa([x,_],
[
 [x,1],
 [
  [x,2],
  [
   [
    [x,3]
   ]
  ]
 ]
], A).
A = [[[1, 1], [x, 1]], [[1, 2, 1], [x, 2]], [[1, 2, 2, 1, 1], [x, 3]]].
If given 1, 1’s address would be 1. So, [1,1] is 1 in [[x,1]], and so on.
61. The immortal used a predicate if a term depended on one before it. I transformed data collected with subterm with address. I collected data in the form {[Address, Term]}, where {} meant a repeating list. I found all the pairs, took the term’s second argument, added one, and returned the pairs. If I had needed to renumber the second argument, I would have used numbers//4 or a predicate to do this.
62. The immortal combined or divided addresses. I substituted subterms with addresses back. I pretty-printed the term with subterm with address. I could represent arrays in this manner. I could represent arrays with addresses, saving memory and enabling transformation and compression.
63. The immortal ran sub_term_wa(1,{{1}},A), with the result A = [[[1, 1, 1], 1]]. I customised subterm with address to work with different types of brackets. For example A={B|C}, A=(B|C) or A=<A|B>. In some cases, A=/A|B\\ was allowed. In addition, [A|B] in the predicate header or call could be replaced with this terminology.
64. The immortal wrote the Prolog interpreter in Prolog. I customised subterm with address to work with “|” (the pipe symbol). I changed “|” to &(|), which was reserved. I processed the symbol like any other with list processing. I wrote list processing predicates.

65. The immortal compiled the algorithms for different processors. I updated the algorithms for different processors. C was compiled for a particular processor. I converted to C. This converter was not writing the compiler in C but converting the Prolog code to C. Prolog was a good brand and easy to think of.
66. The immortal deleted redundant constants both collected and processed. I skipped constants if they were already there. I found cases of constants always being matched and ignored them. If hard-coded data always matched and was unnecessary, I deleted it. Data was tested, for example, after collecting and processing it, in findall.
67. The immortal deleted a first constant comparison given specifications. I didn’t verify previously verified constants. If a constant was compared with, I removed the following unnecessary comparisons of that constant. Further comparisons should only be deleted if all possible first comparisons were found. If a first comparison repeatedly seemed excessive, the algorithm notified the programmer.
68. The immortal argued that the imperative procedural programming language C was faster than the logical programming language Prolog. I converted Prolog to C to run it faster. The Prolog interpreter only gave the first correct answer. Findall, used to collect all correct answers, was divided into data collection and processing parts. Functional decomposition into a collection part avoided the need for logical programming, and functional decomposition into a processing part avoided the need for logical programming because possible failure within findall was replaced with if-then.
69. The immortal designed software that optimised programs before running them, especially those labelled not yet optimised. I familiarised myself with assembly code and optimised code for various machines. The multiple architectures had different register state machines. As an aside, I devised a reverse engineering algorithm that uncompiled programs from an assembly language into C and recompiled them into another assembly language. In the future, a chip with a reduced instruction set performed some calculations more quickly, while another chip had more features, and these chips were used in different cases.
70. The immortal compiled Prolog for smartphones, visors and other operating systems and ran it online. I optimised assembly code for various machines. I uncompiled it to Prolog. I removed unneeded code at the algorithm, predicate, and variable levels and reused libraries used by other algorithms. When compiling Prolog, only needed predicate dependencies were used, and all data was compressed into reused, program-encoded, binary form.
71. The immortal checked the human-crewed space vehicle and met the software health standard. I deserved the spiritual A for the data deleted during optimisation. This technique was commonly used for spiritual meditation, time travel and medicine while teleporting across the unit (universe). It indicated the data spiritually, and these ideas were switched on. Space travellers completed longer forms of these ideas daily in each precise teleportation location and relaxed the whole time.
72. The immortal warned the user whether each change had passed the tests. I edited the Lucian CI/CD document in a “diff” view. I read the changes to the files on one page. I clicked on a document, edited it, and viewed the changes. In addition, I instantaneously ran a pipeline to check the changes, with non-permanent pipelines to warn whether changes on the way worked or not.
73. The immortal found efficient algorithms assembly language with Combination Algorithm Writer (CAW). I wrote the C compiler, with libraries for each command. It was faster because it had fewer commands, such as arrays, not structs. Structs were converted into arrays. Programmers could see the C code without structs. Contrary to this, I converted Prolog code to assembly, which didn’t necessarily require CAW. However, CAW could find code for different number lengths.
74. The immortal simplified logical, mathematical, and database (set-theoretical) formulas. I found efficient algorithms in Prolog with Combination Algorithm Writer (CAW). CAW could find simple Prolog code, which could be converted to C and assembly language. Arrays were divided into smaller arrays and converted into assembly language. I reverted to mathematics to speed up Prolog data processing, for example, SLD processing to make non-recursive functions in line.
75. The immortal critically transformed the program, removing buggy or unnecessary features. I simplified the data. I recognised the program within the data. I simplified it, notifying the user of bugs removed. There might be programs within the program’s data, and so on. Programs should all be top-level.
76. If possible, The immortal converted Prolog called through the shell into inline code and compiled it as a single unit. I focused on the first necessary outputs. I took out writeln and other commands with no verifiable output in Lucian CI/CD and put them in later, notifying the user of this. Writeln, etc., were additional features activated with optional modules. As an aside, I kept track of the identification numbers of transformed clauses in Lucian CI/CD to preserve their order in the algorithm.
77. The immortal found the optimal array length to wrap long strings into new array lines. I counted the size of the string in assembly language. This length was stored in a variable describing the data. It was in numeric form (it was possible to read and run code in one form and convert it to the other). Once the Prolog with the code handling the string length was compiled into C, it could be converted into assembly language.
78. The immortal changed numbers//4 in Prolog to an iterative loop in C. I used C structs instead of arrays for complex data. I represented the short-form C algorithm with structs and the long-form C algorithm with arrays. I converted between them. I eliminated unnecessary elements of structs or made optimisations. I invented a form of C where the first element of the array was numbered 1, not 0.
79. The immortal stored hierarchies as list and item numbers, where the list numbers pointed to further lists of items. I used C structs to represent lists of lists. I converted the struct to an array. I used numerical pointers as nodes in the hierarchical struct. I hashed (reused) data.
80. The immortal converted the append into long-form Prolog and a C program. I identified different repeating structures. I found repeating lists and items. These items may be Prolog variables, not dealt with as C variables, but decomposed or built outside the Prolog predicate header. They may be in the short-form Prolog header but not the long-form Prolog header.
"]