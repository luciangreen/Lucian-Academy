University 1 - 1

1. The lecturer processed the data in bulk, converted a formula to an algorithm, and found the program from the user interface. I worked out the future algorithms from the types. The data structure, formula, or output type helped produce the algorithm. I found patterns in the transformation from input to output, such as pattern matching or mathematical formulas. Alternatively, I started by identifying a formula and inferred input and output.
2. The lecturer modified some sentences with cultural references and algorithms with language-specific grammars. I developed the bulk Cultural Translation Tool. I translated the documents into other languages. I checked off the sentences that were the same when back-translated. I asked the user if different sentences had the same meaning as the original and kept these variants to check other languages.
3. The lecturer kept track of sentences that hadn’t worked and kept sentences that had been translated correctly. I developed the tool to translate an algorithm into another language. It could help bulk translate documents into other languages. I translated the document first. Then, I translated sentences the user had modified to be more straightforward.
4. The lecturer always started with exact types or a list of list of types. String concat was similar to append in that it could work out the output of get token-style parsing of strings containing string variables and constants. I represented string_concat as “:” and appended it as “::”. Different types could be inputs into string_concat. For example, A=a: a produced A=a: a. Alternatively, aa=A:a produced A=a.
5. The lecturer broke apart two string expressions, equalling each other, to debug the expression. I stated that a string such as A in aAbBc=DEc could have zero or more characters. I made inroads from the edges. Then, I found all combinations of solutions. I could specify string lengths.
6. The lecturer started with a list of types, in this case, A=b and B=b. The algorithm began by finding the number of times the minimum lists could fit into the string. Then, it tried to find matches until all the matches had been found.
7. The lecturer guessed the type from given constants. I tested compatible commands. I found the type of the called predicate and the call. I selected a consistent fit from the call to the called type.
8. The lecturer turned off the need to define some predicates. I guessed the processed list would be defined. In addition, I assumed output would be preferably defined. I preferred to warn about rather than make allowance for an out-of-place undefined variable. I prefer data to be defined as soon as possible.
9. The lecturer changed "a(A,B,C):-and(A,B,C). and(true,true,true)." to "a(A,B) :- A,B.". I tightened the type of the called argument from a possibly obsolete output-input pair or a non-defined input-output pair. The former, for example, "a(O):-b(O). b(i)." can be rewritten "a(i).". Ideally, input should lead to input, and output should lead to output. I converted logic-containing rules to logic.
10. The lecturer gave the sort algorithm as a type to help generate data. I simplified the non-deterministic list of types to the most useful ones per predicate (for example, ones that used each command in the interpreter). For example, the interpreter may have string, atom and number commands. These had the same types as themselves. I ventured to suggest random input for a sort algorithm.
11. The lecturer continually tried to reduce to binary. I found the algorithm’s types and then wrote tests from them. I reduced the algorithm to minimal logic, including types. I made inroads, working out and simplifying parts at the start or end that the algorithm always parsed or didn’t need. I determined the algorithm’s properties and simplified it, like lazy evaluation, using data or the algorithm, prompting optimising the instruction set.
12. The lecturer found additional possible new tests to test new features. The immortal suggested corrections to incompatible tests. First, the algorithm found types to check tests against. If an already present test didn’t fit any types, then all or parts of the input compatible with the type could be used to find the spec. The algorithm could find the closest type and modify the test.
13. The lecturer signified exact data lengths and types, requiring grammars. I checked the human-written tests against the types. For example, the string a, which may recur in types, may have different lengths with different results. It may be better to use constants or specific lengths. The constants would signpost sequences in the string, making it easier to parse.
14. The lecturer added zeroth rows and columns. The string expression a = string expression b could contain whole algorithms. For example, similar list expressions could find list(list(number a_n_m))->flat(list(list(a_n_m))). Or they could find items using a heuristic. For example, the maximum number or the sorted list could be found. This heuristic may be part of the algorithm, transforming matrices.
15. The lecturer explained that the item was transformed and put back. Simplified expressions were a new programming language. I extracted items with member or subterm with address. I wrote connections between equal expressions and extractors, such as list(max(list1)). I extracted information twice when correspondence was needed.
16. The lecturer explained how the algorithm should work in plain language. I explained that the item was transformed and put back. For example, a type statement with a formula was list([a where a member([b, C], a) and C is replaced with C+1]). Or C could be compared with a value inside or outside it. Or only a list([b, C]) could be returned, or addresses of [b, C] could be recorded before substituting back.

17. The lecturer called recursive predicates recursively with nested data or data with restarting or continuing output. I produced several outputs with Spec to Algorithm (S2A). Instead of one output with several variables, I produced several outputs. I could have negative results (results that failed) to shape results when porting S2A specs to CAW by creating conditions and sub-conditions in clauses and sub-predicates containing the “not” operator. S2A and CAW created predicates with multiple outputs, such as processed and output lists.
18. The lecturer explained that the compiler attempted to optimise code before running without “trace” to improve performance. I used S2A to optimise Prolog. I rewrote the Prolog code based on its specs from tests or types from the original algorithm. The type finder found a certain number of possible outputs with data for each predicate, including dependencies of predicates. Optimisation involved contracting pattern matching to a minimum number of statements, where intermediate CAW statements transformed variable values for further pattern matching or output.
19. The lecturer noticed that the generated code represented multiple predicates, and the generated code represented the algorithm bottom-up to simplify the type generation needed to produce S2A specs to produce the code. The bottom-up method should only be used if the algorithm can’t be found from S2A specs for the whole algorithm, where the commands’ types are broken down instead, and the code is found. S2A optimised code by finding recursive patterns and separating and finding constants for specs with the same shape, where character-breakdown was completed if code couldn’t be found for non-character-breakdown. In this case, all strings, atoms, numbers and compounds were broken down into characters and variables representing these characters were tested for relationships. These recursive structures found and simplified relationships, producing code that ran with the same results as the original and could replace it.
20. The lecturer used types within CAW to speed up command selection before testing. I used CAW to find Prolog commands for parts of S2A specs that S2A couldn’t resolve in optimisation. The decision trees of CAW commands were tested with type statements first. I used trial and error to find rules to accurately find the context for commands, including mind-reading, artistic license, pattern-matching, and recent commands. I created a new command, down to item and character level, to achieve a goal using S2A.
21. The lecturer drafted S2A (with expanded or optimised statements in the form A=B) and loop Prolog commands with “for” or “while” syntax that compiled to C. Using S2A eliminated the lag of using predicates, improving performance. I eliminated expanding to predicates, where expanding to predicates would cost performance if they were part of recursion. S2A was efficient enough for optimisation and, together with recursion-as-loops, could compile and run speedily in C. Recursive structures were reused. CAW commands were not embedded in them but found afterwards in a cycle with S2A until unresolved variables were resolved, and recursion-as-loops were required even with S2A because of CAW.
22. The lecturer wrote code using S2A and converted it to an expanded form for terminal predicates but left it the same for compilation for performance. Expanded code was only for publishing, as it was easier to understand and manipulate. Students and workers could write and use S2A to speed up development time and learn about optimisation strategies, improving performance and code quality. Programmers could read predicates online, extending documentation with examples and automatic code selection and debugging assistance. Premium code checkers helped users finish complex tasks with perfect results.
23. The lecturer converted base cases to exit conditions of loops. I converted non-deterministic code (predicates) to loops for speed. These loops were contained in predicates and resembled for- or while-loops. This method required that variables be renamed and conflicting variable names be corrected. Loops rather than predicates helped warn on overlapping loops and convert recursion to efficient assembly code.
24. The lecturer published S2A as compiler research and trained a neuronet on it. I minimised and simplified the S2A, CAW, and recursion-as-loops-generated code. This step briefly required converting to predicates for DFA minimisation and simplification. In addition, recursive structures and mappings in S2A calls and reused code in predicates were modularised for minimisation and implication. If S2A calls could be replaced with fewer commands, this was done to improve the algorithm.
25. The lecturer wrote an algorithm to interest the no-coder in enough (not necessarily computational) details to develop various specifications in natural language, such as sentences, tables, order of words or other properties that one wanted to transform. I “wran” (sic) or wrote/ran the algorithm in a creative process involving making critical decisions, learning all the most essential types of bug corrections (which one could walk through), finessing code to work professionally and exploring options to share or commercialise the code. Robots, workers, students or hobbyists could walk through development and training demonstrations or texts and incorporate the code or write research as a response. By “wrunning” (sic) the algorithm, the user could optionally specify the algorithm in human language and not experience the code. The user could write a code “wrunner” (sic) with another “wrunner” (sic) and take responsibility for lists of ideas they wanted to “wrun” (sic), which they wrote an algorithm to help them collect automatically, and “wrun” over time.
26. The lecturer wrote a guide algorithm to help add, change or delete S2A call items and to verify the changes, judging when the changes had finished to check and possibly brief the user on unfinished changes if they had gone away. I output comments explaining the recursive structure and mapping elements used in the S2A call for easier understanding and modification. The recursive structure contained nested recursive structures and elements, which were formatted with indenting and labelled in comments with examples of their expanded form. In addition, the mapping of input to output recursive structure addresses, containing pairs of origin and destination multi-dimensional addresses of term elements, gave comments with the variable names from the recursive structures and their contents. This S2A command and recursion-as-loops could be part of a programming language to build and test prototypes quickly.
27. The lecturer regularly backed up essential files and unsaved and saved versions during development. I first wrote specifications, generated code, made refinements, tested, and ran, all of which could be smoothed by checking that the specifications entered and re-entered were in the correct format, were enough, contained required negative cases, and were backed up if needed. All of this could be communicated using natural language and interactive simulations of the algorithm. The colours of part of the algorithm’s data flow became the setting for correcting questionable, poorly constructed or inefficient code. S2A helped correct inefficient code, conflicting variables, and logic structure flaws. It also corrected inconsistencies in the design or format of code, including command selection, indices, reusing predicates, simplifying predicate use, keeping a checklist of items to do and remembering one’s progress during the time.
28. The lecturer expanded recursive structures, using separate ones before substituting data into them because substituting into a term was easier. In S2A, I referred to existing recursive structures instead of creating new ones. These structures were referred to once as part of recursive structures, except when there was a break, they were at different levels or not in a recursive structure together, so a separate recursive structure was pointed to—the new format contained dependencies of pointers rather than a nested term. Near misses or inconsistencies in the recursive structure were noted and brought to the user’s attention or corrected. For example, one-off specs in either the shape of input or output compared with many others, unusual item type or change in type (variable or constant), or a later change leaving inconsistencies were caught.
29. The lecturer expressed that breaking into characters was expensive and only did it when necessary. I only broke elements into characters if needed when optimising them. I transformed the original algorithm into S2A and CAW code stages, where S2A code was pattern-matching, and CAW was unpredictable code such as (+). If the CAW code in a stage broke down into characters or compared them with a value, breaking down to characters was required, and stages were affected by the variables introduced. I checked whether the S2A specifications required breaking down into characters by checking for unusual, unknown variables and then breaking into characters to try S2A or CAW.
30. The lecturer put the answers away. I stated that if elements are broken into characters, it is only for that pattern-matching S2A call. The pattern-matching S2A call can be broken into substituting data into the recursive structure and mapping input to output. A CAW command was inserted if one needed to be inserted between these. CAW commands included operations, verifications, and comparisons between input and output.
31. The lecturer optimised the algorithm with Spec to Algorithm (S2A), using existing commands rather than CAW for processing speed, in contradistinction to finding the algorithm using S2A and CAW. Breaking into characters of elements before S2A processing needs to be done before finding unique variables and constants to include variables from multiple computations. The algorithm sections, mainly where variables were unknown and S2A worked, must be broken down into characters and labelled for breakdown. These sections were then broken down across the spec at this point of the algorithm. The whole algorithm needed to be worked through bottom-up with S2A, with variables being copied to new S2A calls but one not being concerned with unique variables and constants being computed for the whole algorithm simultaneously.
32. The lecturer minimised the code and data structures and mapped the output to the user’s code and data structures at the end. If S2A produces a unit production A1=A2, I noted it, then collected instances of this chain of variables from the sequence of S2A calls and removed the unit productions A1=A2, etc. This removal might not be necessary because S2A moves needed computations forward. Pattern matching operations are already grouped, with only necessary CAW commands between S2A calls, leaving no unbroken chain of A1=A2 commands, assuming variables are grouped into those needed to move together. There are no individual variables left unaccounted for in a pattern-matching operation. I magically used the S2A code to compute the answers in the algorithm at the earliest opportunity, even though the user appeared to receive the answer by tracing through the existing code. Even though the existing and S2A codes do the same thing, the performance improvement from optimising with S2A may be minutes or hours.
