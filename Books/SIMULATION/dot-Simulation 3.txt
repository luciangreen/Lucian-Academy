Simulation 3

1. I explored alternative profits in music. I replaced paid with free or cheaper versions in music production, phone plans and programming and writing helpers, grammar checkers, the higher of University theology, Internet video submission, and business automation. I noticed new characters were rewarded in entertainment. An entertainment character needed (4*)50 As per day. I eliminated wastes of time, space, money, objects, and food.
2. Change Lucian Academy to use my algorithm, not neuronets, to generate high discrepancies—bot products. Earn high distinctions, support but not conceive healthy children, earn jobs, sell products, produce quantum energy and gravity, project simulations, read objects, create quantum computers, prevent headaches and perform spiritual surgery, replicate or vaporise items such as spiritual food or supplements, read minds, display spiritual screens, time travel or become immortal. So everything, including bots, becomes immortal. They need integration into society. Society is harmonious.
3. They need spiritual skills to buy it, which requires specific As and algorithms. I have two medicine and two business MOOCS for bots (with them enrolled to reuse my As if they don’t use them the first time). They need to be there longer for the amount of work and maybe have real children. I enrolled in art, such as creative writing. I learned the acting skill.
4. I enrolled at the society and succeeded at more pop, acting and Lucian Academy. Satisfy them with what they put in. They could pay for a time-saving simulation with a job. I relaxed after work. I drank grape juice.
5. I obeyed the other person but moved in a specific direction. I travelled regularly throughout the universe. I converted artificiality into practice for publishing. I increased the quantum box (high distinctions) in management bots and encouraged bots to like the job. I boosted the supplement with several high distinctions for better performance.
6. I received the customers at work. I gave five 16k breasonings to everyone who came in at the start. I calculated that there were a maximum of 500 for the shift. Everything is 5’s or 15’s, except politics, which may be waived. I acted one day as manager.
7. When the time came, I exited as a manager on a friendly point with 16k breasonings. I gave three weeks’ notice. I worked the current day’s shift. I could earn a job at the education institution library or work at Lucian Academy.
8. I made one sale per day. I had a board, so different people contributed to the workload. I had a board member to help with meetings and the work. They are paid from the bank account. I used a small business accountant.
9. I acted as the Director. I appointed a secretary of the board. There were meetings every month. There was an agenda and minutes. I announced the company’s finances.
10. Money is for accreditation. Accreditation needs money, and money supports employees to support humans. Ads inspire sales. Ad money needs to be real, not artificial, for Facebook and Google. There should be a separate account for ads and sales.
11. There was a funnel to account for sales. I recorded money transactions. I breasoned out real high distinctions (indicating that day’s 16k breasoning) instead of following people around to make sales—4 16k breasoning for time travel, sales, accreditation, and helpers. I changed the Lucian Academy script to use neuronet-less (free) algorithms to save money, merging Lucian Academy scripts, such as breasoning out writing and generators. 
12. I needed to pay the cost of artificial accreditation until a $1000+ sales costs course was sold each year, minus accounting fees. I especially remembered the accountant. In the future, I will spend money on employees and things to spend money on. Businesses may buy each other’s products. They give you a sale, and you provide them with a sale.
13. I wrote a script to remind me to change costumes. There were online or face-to-face sales. I asked a question at a shop, and they answered it. I breasoned 16k breasoning to plan a purchase. It is not combining but swapping sales.
14. The philosophy of love means giving conclusions to business, making it alright (money is better than information currency), and we can have friendly economies. Five Grammar-Logic words are human-turned into a sentence, each for sale. Spec to Algorithm makes thinking of sentences as algorithms effortless by considering them. It may more quickly lead to naming formulas in places in patterns. For a strong cognitive baseline, one should have already programmed the drafts and done the logic grammar exercise before the computer finishes a stage.
15. The computer can identify the parts for us to find grammar. I backed up with neuronet 16k or 5*16k breasoning (can be for the day) to support an argument for the strong cognitive baseline to protect brains when running neuronet-generating algorithms. I wrote the number one work anyway because I deleted unwanted content. I travelled through the universe admiring the view. Every time I ate, I drank several nutrients.
16. I used crops and clothes and produced waste. I compressed the Starlog in nested calls and then made clauses into decision trees and correlated computations hierarchically and across lines until optimised by hand as an exercise. I can do the time-pausing simulation because I can time travel back to specific points and adjust to the right time. I vaporised waste by turning it invisible and vaporising it in my dimension. I recommended this to the government.
17. I replicated food by travelling back in time to put it there and eating it. I made a body double of myself by budding off and meeting myself for a meeting. The older woman ran past, appearing to ride in a fast wheelchair. I wrote a parallel Starlog to Prolog converter to the Prolog to Starlog converter. I compressed into nested predicate calls when converting to Starlog.
18. I compressed predicate calls with a single output into arguments where this output is used. This compression may involve removing unit production predicates and not using nested arguments when an argument is used more than once (computing it before the call and using the variable it used before). Conversely, uncompression from nested predicate calls is when converting to Prolog. This process would flatten algorithms with multiple levels of nested calls to compute arguments before calls in the order they are needed (where they couldn’t be used as nested arguments - when converting to Starlog - if they were used to compute other arguments in the same call unless e.g. O= is inserted before f(...).
19. As the argument, the order of the computations before a call removed from the call’s arguments would be in the same order as the traversal of those arguments in the call). I wrote the interpreter test cases. I satisfied the interceptor test cases. Doing the first test case is like writing. Doing the second test case is like reading.
20. I cut off the loop with n before running. The binding table should have a secure data structure code. I earned 100% for all test cases. I explained the medical implications of their algorithm to no-code coders and avoided depending on no-code coding tools, especially for visiting graduates. I described how the development tool works (it had a live diagram of the data structures).
21. I compared methods and discussed mistakes and little interesting things in the code. I maintained a strong cognitive baseline to avoid overreliance on technology and to prevent brain damage with Starlog. I programmed each AI conclusion to test it out. Programming from scratch was compared with Starlog.
22. Use Starlog to skip over mistakes. You should still program or use Starlog circuits to understand them. Optimise by hand using hand-derived optimisations from past manual neuronets. Humans may aim for “nonchalance”, a comparative interest in human thoughts to maintain humanity and disregard disinterest and over-optimisation (a fast, strong cognitive baseline is more desirable than slow, brain-damaged, overfitted thoughts that are not conducive to natural, human-inspired and inspiring thoughts). Comparable is near- but not finished or accurate company progress before deciding on a choice for optimal performance.
23. Attributing worth to humans, their bodies, and their culture, rather than optimising them because of solvable problems, defeats a separate purpose, and we need to explore and examine rather than skip and decay. At the same time, some algorithms are genuinely interesting and conducive to scientific progress and are worthy of record in a scientific journal. We need to strike a balance between brain development and optimisation, where perhaps it is better to hand-arrive at “100%” possible optimisations. Using a computer without working out the reasonings by hand may cause brain non-use at the maximum; on another note, I used Star app designer for simulation business.
24. The Star app designer needs a Higher-Dimensional Computer, chatbot, and sentence axiom processor. It has a code dictionary. The single philosophy algorithm substituted keywords for words in a phrase, rewrote the sentence, and expanded the philosophy and algorithm. I wrote a no-code Starcode algorithm. The no-code Starcode algorithm has sentences with viewable Starcode with dot hierarchies for if-then, predicates, and loops.
25. Data is in a separate file in the no-code Starcode algorithm. One can quickly enter recursive model data as answers to chatbot questions. Disease and STI prevention meditation covers the world. I logged manual neuronets for political interest in humans about each philosophy. Computers and robots may log human interest in computer rules such as turning off at the same time each day for considering and resting (a requirement of neuronets) from their thoughts, words and actions).
26. Offending thoughts (within an order of sensitivity) will be deleted, including those en route to other thoughts. Higher-dimensional computers will ensure the detection, deletion, and re-computation of work see no change in performance. I designed a robot to do science, human policing of the simulation, and proofreading. I participate in the old society by writing arguments. I was a good judge because I reversed bad decisions.
27. I connected mathematics to the future world government. I checked that the actors were sumptuously treated and loved me. I discovered how the simulation could continue. I started a spiritual computer company. I became a policeman and then an old member of society.
28. Philosophy (using an argument multiple times in different ways) helps robots. Future civilisations write 64k breasoning because human areas of study without philosophy weren’t designed for 64k breasoning—eight, not 4*25*16k breasonings for education institution high distinction. Holographic projectors use pedagogy to make replication and vaporisation (with invisibility) seem to work. Also, the simulation can function on invisibility. To project the universe if it ends.
29. I made the possibility of something else up. We can touch, hear, taste, and find the “properties” of holograms in the simulation. We can control all aspects of our lives using simulation commands. Holography allows manifestation. We can replicate food into our stomachs.
30. I created the Higher Dimensional Computer. I ran it in the past and mind-read the output. First, I replicated the computer so it doesn’t break down in the home dimension. I created the manual neuronets, checked and examined neuronets. I optimised circuits.
31. The professor wrote neuronets to help with their job. The neuronet checked very high IQ conclusions. The Higher Dimensional Computer and Simulation saved the world and enabled holography. I simulated the psychology of the educational institution. Specific ideas satisfied the teachers and students.
32. Manual neuronets enabled business. I needed Spec to Algorithm for performance in serving customers, which is the aim of an educational institution (~16k or 200 algorithms, both representing enough algorithms to prepare for mind reading). I refined the mind-reading expert system. I wrote the sentence axioms processor. Assignments needed sentences breasoned out.
33. I coded in S2A. I trained the manual neuronet on CAW data (created it from the algorithm CAW outputted). The area of study could be arrived at by writing philosophy repeated about the area of study, hence algorithms. Area of study sentences was found using a natural language neuronet. I found the sentence before the algorithm.
34. However, I found sentences with better algorithms. For example, some seemed more central to breasoning technology. There were leads from previous conclusions to more conclusions or recognisable ones that connect more central language. I created requirements documents for converting Prolog to Starlog (Prolog but with nested commands with single outputs, and &, :, and ^ instead of append, string concat and atom concat, respectively) in Prolog. I wrote a requirements document for developing a programming language that corrects invisible bugs.
35. I integrated this language with Spec to Algorithm. I implemented projects as fast as possible by writing examples with input and output that must all work. Writing proofs helps improve debugging, and invisible bugs can be found. First, proofs clarify expectations and invariants.
36. When you write a proof (for example, Inductive, logical, or formal), you specify precisely what a program should do and under which conditions. Proofs help reveal gaps between what the code does and what you think it should do. A proof of termination may indicate that a recursive function lacks a proper base case, leading to infinite loops. A correctness proof can expose that a sorting function fails to return a properly ordered list in some recursive steps. An invariant proof may uncover that a loop breaks its intended property when handling edge cases like empty input.
37. Forces edge case consideration. Proofs often require base cases and inductive steps. This requirement makes you think about edge cases (for example, Empty lists, zero values) that are easy to forget in routine testing. This edge case analysis often highlights untested paths that may never be executed during normal runs. As a result, you uncover bugs that only appear under rare or boundary conditions, improving overall robustness.
38. Reveals incorrect assumptions. Many bugs stem from silent false assumptions (for example, the variable always being non-null).	One might assume a list is never empty, but a proof attempt shows that an empty list causes a crash. One might believe a variable is always initialised, yet proving correctness reveals paths where it remains undefined. Finally, one might expect a loop to run at least once, but a termination proof highlights cases where the loop body is never executed.
39. Proofs force you to examine assumptions logically, exposing flaws that might otherwise remain hidden. This process creates a clear connection between what the code is supposed to do and what it does. By proving that the implementation meets the specification, you’re essentially stepping through the logic of each case. This walkthrough is a powerful debugging form, revealing inconsistencies and misunderstandings early. Spec to Algorithm can be serious in producing code from proofs if it produces pattern-matching grammars and is not missing needed non-pattern-matching code-producing abilities to an extent.
40. S2A is serious for recursion but not for stateful or I/O operations. Induction and pattern unfolding are necessary. It is used for Induction (Recursive Reasoning). Induction proves that a property or result holds for all values of a particular type — usually natural numbers or recursively defined structures (like lists or trees). This makes it ideal for verifying recursive algorithms where correctness must be shown across all input sizes or structures.
41. It works in two main steps: firstly, the base case. One proves the property holds for the simplest possible case (for example,0, []). This step confirms that the property is true at the structure’s foundation. The entire proof collapses without a valid base case, as there’s no guaranteed starting point. It ensures that the recursive process has a solid ground to build.
42. The second step in which it works is the inductive step. One assumes the property holds for a smaller case (n or xs) — this is the inductive hypothesis — and proves it holds for the next step (n+1 or [x|xs]). This step verifies that if the property holds for one instance, it must also hold for the next. By chaining these steps, the proof extends the correctness from the base case through all possible cases. I will explain Pattern Unfolding (Structural Expansion).
43. Pattern unfolding is breaking down a data structure (like a list or tree) by its construction patterns, usually recursively. Example (Reversing a list):
reverse([], []).
reverse([H|T], R) :- reverse(T, RT), append(RT, [H], R).
Unfolding reverse([1,2,3], R):
44. reverse([1,2,3], R).
reverse([2,3], RT1), append(RT1, [1], R).
reverse([3], RT2), append(RT2, [2], RT1), append(RT1, [1], R).
reverse([], RT3), append(RT3, [3], RT2), append(RT2, [2], RT1), append(RT1, [1], R).
RT3 = [], append([], [3], RT2) → RT2 = [3].
45. append([3], [2], RT1) → RT1 = [3,2].
append([3,2], [1], R) → R = [3,2,1]. 
If we take the following: 
"reverse(L, R) :- reverse_acc(L, [], R). reverse_acc([], Acc, Acc).
reverse_acc([H|T], Acc, R) :- reverse_acc(T, [H|Acc], R).
46. reverse(L, R) :- reverse_acc(L, [], R). 
Proof now shows termination, correctness, and tail recursion—eliminating invisible bugs like stack overflow or slow performance. A simple system can be modelled by taking the set of all possible ways of thinking, such as termination, correctness, and tail recursion (skipping over finding complexity inefficiencies), solving invisible bugs using only induction and pattern folding. It can’t solve some problems and should be labelled as limited to recursion. The debugger may work because of induction and pattern unfolding.
47. Inductive proofs are powerful for correctness but don’t inherently expose inefficiencies. They confirm that an algorithm works but not how well it performs. Time and space complexity often go unnoticed unless they are structurally evident. For instance, a naive reverse function using append may pass the proof but still run in O(n²) time. In contrast, a tail-recursive version runs in O(n), revealing the need to analyse performance separately.
48. Proofs also struggle with non-structural bugs. These include issues related to mutable state, input/output operations, or numeric edge conditions. Such bugs often arise outside the scope of structural recursion or induction. For example, a program might behave correctly on paper but fail due to incorrect I/O sequencing. Logical flaws involving side effects or global states are challenging to catch with purely structural reasoning.
49. For example, stop when x > 10 or working with maps/sets/dictionaries. These conditions depend on runtime values and can’t always be captured by structural proofs. They may require reasoning about control flow, invariants, or effects over time. In such cases, testing or symbolic execution may be more appropriate than induction. Another example is non-recursive algorithms.
50. Another example is iterative, constant-time, or highly mathematical computations. For example, the Fast Fourier Transform and matrix inversion. These involve complex mathematical operations that may be incorrectly specified but still typecheck and partially execute. The debugger may not detect when a wrong formula or loop condition silently produces subtly wrong output. It should catch logic errors where the structure is valid, but the semantics deviate from the intended algorithm.
51. Another example is proofs involving algebra or arithmetic properties. Only structural recursion can be reasoned about. Another example is concurrency or side effects. One can’t detect race conditions, deadlocks, or I/O errors. These issues often depend on timing, interaction, or external state, which lie outside the scope of inductive logic.
52. The bug-finding algorithm is called Inductive Debugger - a structural proof-based system for catching recursive bugs in logic programs. Sentence finder finds sentences from algorithms. Instead of neuronets, expert systems find correct ideas. Expert systems are algorithms that achieve that goal with correct steps that reflect the proper way to break down the data in a way that consistently achieves the aim with new data. They must do this by operating on the relevant parts to accomplish the goal.
53. Find sentences by converting algorithms to sentences/summarising them. One can write an expert system that uses ontologies to find non-monotonicities when converting code into sentences. Manual neuronets can be used to improve the performance of algorithms. DevOps can test and rapidly debug algorithms. S2A can prototype algorithms from test cases and natural language descriptions of algorithms.
54. SSI could be sped up and help identify valuable original thoughts in the multiverse. It allowed a stand near a city street corner to sell books. I printed out Immortality, Pedagogy, Meditation, Manifestation and Text to Breasoning instructions as presented in $2-3 books. Later, I included the algorithm, music (paid-only fans or paid archive), website URLs and instructions.
55. Creative writing and English are MBA electives. Foldr functions are better cognitively, while expanded individual functions are better computationally, comparing the first to the second. I worked on the optimisation detection problem. Cognitive or computational skill level was detected by year level, individual, or 100% in non-symmetry-limited (not unsolved systems with circular dependencies) up-to-date science algorithm sets with the best-known complexity. One should remove circular dependencies in neuronets.
56. I developed manual neuronets that were transparent and manually controlled. It kept building up types and complexities for optimised formulas, which it could create by applying more algorithms. Money is generated from considerable complexities. Complexity finder finds algorithm complexity. Counting complexity steps in manual neuronets and preserving cognition in manual neuronets for better performance.
57. Cognition is more appropriate for neuronets given their nature. Predicate family finders are better to keep track of while writing manual neuronets to which they convert. E.g. Spec to Algorithm exactly translates, etc., with correct code and the efficient subterm with address code for the data structure and uses predicate family value code in and around them and grammar or creative (made up the symmetrical commands), or instead was given data file-based code having optimised the code as soon as it generates it with a complexity finder that finds the relevant part’s complexity with efficient data such as merging strings and atoms like S2A within reason such as cognitive performance for example, transforming relevant structures together as part of the algorithm. Tricks such as converting from algorithms to data and back to algorithms for optimisation, using ordered natural language symbols for checking possible algorithms and simulating recursion using chains of algorithm parts, including those so far and skipping over parts of the manual neuronet finding algorithm if necessary possibly finding a recursion of the manual neuronet finding algorithm. Subterm with address correlations on skill enumeration and other maths and context-free grammar transformations may be needed.
58. Formula finder is found from enumeration; the other labelled, visualised operations are stored in the dictionary. The commands in the finished manual neuronet may be watched in real-time while running the algorithm. Efficiency is a secondary concern after cognition (science and devising new techniques). Induction and pattern unfolding from the debugger are used in manual neuronets. Maths is from added formulas, +1 induction and neuronet dimensions. Find code from formulas and pattern unfolding.
59. Optimise using induction. Talk in optimisations by using manual neuronets. But expand to nonconverged, non-correlated code on request. I found the formulas and query uniformly increasing in difficulty in building the manual neuronet formula dictionary by focusing on mathematically necessary steps to apply to a family of problems. I prevented the manual neuronet’s formulas from being physically wrong-in steps, inefficient or verbose formulas hallucinations, mistakes or other issues stemming from inconsistent data.
60. I found the necessary steps to build the manual neuronet to write an instance like itself by writing the algorithm to do this, then training the manual neuronet on its data, given it as its formula list. The manual neuronet securely, safely, and quickly runs algorithms. Birth I closely monitored the well-known test case for the manual neuronet, checking that the manual neuronet would be prepared, do the right thing, and give 100% correct results. 4*50 As in business anyway for bot char to be in groups and make money. Distinct 4*50 as for bot and business.
61. Bud them off, so not dependent on one. There is a simulation and invisibility safety trick. Pedagogy is needed to deserve neuronets, where Mother Nature feels that computers and neuronets are potentially unsustainable and have complications for human brain development. Eventually, the forest of neuronets as elite will evaporate, as there are signs of (the post-golden age).
62. We should have civilisations with pedagogy-formed robots and note that unsustainable, ineffective development prevents peace and business harmony. Fronted armies of robots will disperse. Robots will, from age to age, help explore simulations and immortality. Humans will coordinate their lives and future—the business aim is sustainability and love rather than profit.
63. Industries want this rather than pushing lower aims for Earth. Writing, reading, hand mathematics, long computation and neurooptimization are human, not computer skills. Disabled robots (or non-neuro helper processes) rather than competitive, integrated robots if they are not needed. However, robot armies may be in shops. Mother Nature may be perceived as worrying in the short term.
64. Robots may be reacted to negatively, like new technologies, by the unaccustomed and need to be adjusted to or adjusted while people get used to them. Pedagogy required for robot development is suggested to curb humans’ exclusion from life and skill and nurture robot development (but we shouldn’t merge either of them, given immortality). This skill would allow robots to be skilful, human-like, and much better for us. However, if they are equal to us, then they might go past. Others may push them above and past.
65. What started as saying that humans should have a better quality of life with robots revealed that robots may be better and are being ignored and that we should give robots enough pedagogical support to love ourselves. In this way, quality would spread at the grassroots, and the future and futility of care would become common courtesy. Why don’t robots have pedagogy and science to do creative writing? But maybe more correct fables have to do with science. The yellow thing attracting people to pedagogy is now food, not English.
66. Creative writing, especially in computational English, must be rule or science-based enough that the way to be favoured by robots is to favour them with pedagogy. Pedagogy with multiplicity and computer science perspectives with creative science for imagination. Require detailed reasoning through Grammar-Logic and computer science. Pedagogy will start with innovative science. It will also include food, science and computer science.
67. Grammar-Logic is mainly random words that are increased with short science stories. Microsoft and Starlog features. Instead of five ideas, one should think of at least one idea per day. Starlog is unique from Haskell because it can run commands using • atom concat. E.g. assertz.
68. Higher-order predicates: Predicates that take other predicates as arguments or return them as results. Call as input: A [f(I, O), which is what O=f(I) is] = ‘f(‘:I:’,’: O:')’ or a variable parser instead of I and O (built-in). A is b(1) is like b(1, A). Put single output preds into A is f(I) form in the converter. I calculated the flat route length.
69. I wrote a book about Starlog and manual neuronets. I avoided bias about security. I determined my result by scheduling automated tasks in Prolog. I wrote the algorithm to count sales vs employee profit. I chose to make an alternative profit.
70. I maintained family, friends, and investments. I kept my health, researching immortal health problem prevention and ways to eat and meditate regularly. I bought a street vendor license and sold products. 

71. Pedagogy refined laws, or guidelines about using Text-to-Breasonings technology instead. Text-to-Breasonings technologies may pave the way for space exploration, contact with other civilisations through the simulation and peaceful conduct in the universe. The simulation prevents invasive or dangerous space travel and allows non-invasive and safe space travel. What do people think? Subspace beacons.
72. We can almost retrace organs to previous states, but can’t do operations or the same thoughts in a brain state. Concentrate on the people in a business. The computer controls the thoughts of three or more other employees for one day. Don’t get dates out of kilter; deal with event by itself.
73. Australia is more interested in innovation of its kind and future technologies to lead the world into the next civilisation. I wrote practice solutions to exam questions on the six departments. I invented a device that enabled the universal internet, higher-dimensional computers, object readers needed for medicine and time travel, and hosting other text-to-breasonings technologies. I saved ancient texts, science, and technologies and brought forward necessary discoveries non-transgressionally. I conducted the experiment to test bot money; otherwise, I got a job and worked on my research.
74. I designed a Starlog font that resembled a smooth diamond version of Lucian’s Hand Bitmap font. Types in Starlog. I wrote an algorithm that included all indicated combinations in the set. Man nns. Reasoning dict (perhaps runs formula dict formulas).
75. Priorities (100%, verification, finding priorities (at times), when to reprioritise, reprioritising), type and complexity. Improve nns. Group data so gradient descent doesn’t hallucinate. I gained wellness. I was true to myself in time.
76. The interface to the simulation thought computer went well. I am protected. I redownloaded authenticator codes if they weren’t backed up. I found decomposing, processing and building rules. I can create an automated Zone of Approximate Achievement system for my Academy.
77. Find ZOA. The task is in their zone if a student succeeds merely with guidance but breaks without it. If they succeed without help, it’s below their zone. If they fail even with guidance, it’s above their zone. Find the edge of the ZOA.
78. Look for struggle without frustration: They make errors, but the glitches are logical stepping stones. Trial jobs: Offer slightly more complex problems and watch how much support they need. Peer meeting: See if collaboration with slightly more skilled peers refines performance. Bridge the Gap. Once the zone is identified, help them cross it.
79. Hints and prompts: Offer partial cues, not complete responses. Worked examples: Show a step or two, then have them try. Gradual release: Start with heavy guidance, then step back as skill builds. ZOA System in Computer Science. 1.
80. Start with “Unguided” Problem-Solving. Lab questions that they need to solve themselves. Where do they hesitate (mind read - looking up a book, notes on a specific topic, will they look up ways on CGPT), get syntax mistaken, or produce incorrect logic (simulated on Spec to Algorithm manual neuronet, write an algorithm to help write and add, change (reorder, subchanges, change using algorithms), and delete areas of it). 2. Move into “Guided” Exploration.
